>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from git://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing Blosc v0.1.4
INFO: Installing Clustering v0.4.0
INFO: Installing Distances v0.2.0
INFO: Installing Distributions v0.8.7
INFO: Installing GaussianMixtures v0.0.11
INFO: Installing HDF5 v0.5.6
INFO: Installing JLD v0.5.5
INFO: Installing PDMats v0.3.6
INFO: Installing StatsBase v0.7.3
INFO: Installing StatsFuns v0.1.4
INFO: Building Blosc
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date — you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.0-rc4
Commit e9c9c92* (2015-10-04 03:14 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing GaussianMixtures
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/HDF5.ji for module HDF5.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/JLD.ji for module JLD.
WARNING: Base.Nothing is deprecated, use Void instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.Nothing is deprecated, use Void instead.
WARNING: Union(args...) is deprecated, use Union{args...} instead.
 in depwarn at deprecated.jl:73
 in call at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 [inlined code] from none:2
 in anonymous at no file:0
 in process_options at ./client.jl:284
 in _start at ./client.jl:411
while loading /home/vagrant/.julia/v0.4/Clustering/src/kmeans.jl, in expression starting on line 63
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.Nothing is deprecated, use Void instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
INFO: Testing Data
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
WARNING: int(x) is deprecated, use Int(x) instead.
 in depwarn at deprecated.jl:73
 in int at deprecated.jl:50
 in kmeans! at /home/vagrant/.julia/v0.4/Clustering/src/kmeans.jl:37
 in kmeans at /home/vagrant/.julia/v0.4/Clustering/src/kmeans.jl:53
 in GMMk at /home/vagrant/.julia/v0.4/GaussianMixtures/src/train.jl:99
 in GMM at /home/vagrant/.julia/v0.4/GaussianMixtures/src/train.jl:32
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in process_options at ./client.jl:308
 in _start at ./client.jl:411
while loading /home/vagrant/.julia/v0.4/GaussianMixtures/test/bayes.jl, in expression starting on line 4
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.635025e+03
      1       1.019971e+03      -6.150539e+02 |        8
      2       9.248022e+02      -9.516891e+01 |        4
      3       8.995556e+02      -2.524666e+01 |        0
      4       8.995556e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 899.5555606811417)
WARNING: float64(x) is deprecated, use Float64(x) instead.
 in depwarn at deprecated.jl:73
 in float64 at deprecated.jl:50
 in _kmeans! at /home/vagrant/.julia/v0.4/Clustering/src/kmeans.jl:156
 in kmeans! at /home/vagrant/.julia/v0.4/Clustering/src/kmeans.jl:37
 in kmeans at /home/vagrant/.julia/v0.4/Clustering/src/kmeans.jl:53
 in GMMk at /home/vagrant/.julia/v0.4/GaussianMixtures/src/train.jl:99
 in GMM at /home/vagrant/.julia/v0.4/GaussianMixtures/src/train.jl:32
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in process_options at ./client.jl:308
 in _start at ./client.jl:411
while loading /home/vagrant/.julia/v0.4/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.082075
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.865410
INFO: iteration 2, lowerbound -3.734125
INFO: iteration 3, lowerbound -3.585514
INFO: iteration 4, lowerbound -3.410132
INFO: iteration 5, lowerbound -3.229424
INFO: iteration 6, lowerbound -3.066081
INFO: dropping number of Gaussions to 6
INFO: iteration 7, lowerbound -2.925606
INFO: iteration 8, lowerbound -2.807644
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.727127
INFO: iteration 10, lowerbound -2.671213
INFO: dropping number of Gaussions to 3
INFO: iteration 11, lowerbound -2.619985
INFO: iteration 12, lowerbound -2.565129
INFO: iteration 13, lowerbound -2.517108
INFO: iteration 14, lowerbound -2.471693
INFO: iteration 15, lowerbound -2.430776
INFO: iteration 16, lowerbound -2.394522
INFO: iteration 17, lowerbound -2.362170
INFO: iteration 18, lowerbound -2.334207
INFO: iteration 19, lowerbound -2.314355
INFO: iteration 20, lowerbound -2.307409
INFO: dropping number of Gaussions to 2
INFO: iteration 21, lowerbound -2.302938
INFO: iteration 22, lowerbound -2.299260
INFO: iteration 23, lowerbound -2.299256
INFO: iteration 24, lowerbound -2.299255
INFO: iteration 25, lowerbound -2.299254
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: 48 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Tue 06 Oct 2015 09:21:45 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Tue 06 Oct 2015 09:21:46 PM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Tue 06 Oct 2015 09:21:46 PM UTC: EM with 272 data points 0 iterations avll -2.082075
5.8 data points per parameter
,Tue 06 Oct 2015 09:21:47 PM UTC: GMM converted to Variational GMM
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 1, lowerbound -3.865410
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 2, lowerbound -3.734125
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 3, lowerbound -3.585514
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 4, lowerbound -3.410132
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 5, lowerbound -3.229424
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 6, lowerbound -3.066081
,Tue 06 Oct 2015 09:21:47 PM UTC: dropping number of Gaussions to 6
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 7, lowerbound -2.925606
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 8, lowerbound -2.807644
,Tue 06 Oct 2015 09:21:47 PM UTC: dropping number of Gaussions to 5
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 9, lowerbound -2.727127
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 10, lowerbound -2.671213
,Tue 06 Oct 2015 09:21:47 PM UTC: dropping number of Gaussions to 3
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 11, lowerbound -2.619985
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 12, lowerbound -2.565129
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 13, lowerbound -2.517108
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 14, lowerbound -2.471693
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 15, lowerbound -2.430776
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 16, lowerbound -2.394522
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 17, lowerbound -2.362170
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 18, lowerbound -2.334207
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 19, lowerbound -2.314355
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 20, lowerbound -2.307409
,Tue 06 Oct 2015 09:21:47 PM UTC: dropping number of Gaussions to 2
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 21, lowerbound -2.302938
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 22, lowerbound -2.299260
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 23, lowerbound -2.299256
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 24, lowerbound -2.299255
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 25, lowerbound -2.299254
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 26, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 27, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 28, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 29, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 30, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 31, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 32, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 33, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 34, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 35, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 36, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 37, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 38, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 39, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 40, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 41, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 42, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 43, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 44, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 45, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 46, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: iteration 47, lowerbound -2.299253
,Tue 06 Oct 2015 09:21:47 PM UTC: 48 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777397964,178.04509222602027]
β = [95.95490777397964,178.04509222602027]
m = [2.000229257775316 53.85198717246104
 4.25030073326986 79.28686694436108]
ν = [97.95490777397964,180.04509222602027]
W = [
[0.37587636119492734 -0.008953123827347077
 0.0 0.012748664777409909],

[0.18404155547483975 -0.0076440490423277455
 0.0 0.008581705166332498]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9844422018986906
avll from llpg:  -0.9844422018984689
ERROR: LoadError: LoadError: OutOfMemoryError()
 in avll at /home/vagrant/.julia/v0.4/GaussianMixtures/src/train.jl:336
 [inlined code] from /home/vagrant/.julia/v0.4/GaussianMixtures/test/train.jl:15
 in anonymous at no file:14
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:304
 in process_options at ./client.jl:308
 in _start at ./client.jl:411
while loading /home/vagrant/.julia/v0.4/GaussianMixtures/test/train.jl, in expression starting on line 2
while loading /home/vagrant/.julia/v0.4/GaussianMixtures/test/runtests.jl, in expression starting on line 7
==========================[ ERROR: GaussianMixtures ]===========================

failed process: Process(`/home/vagrant/julia/bin/julia --check-bounds=yes --code-coverage=none --color=no /home/vagrant/.julia/v0.4/GaussianMixtures/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: GaussianMixtures had test errors
 in error at ./error.jl:21
 in test at pkg/entry.jl:753
 in anonymous at pkg/dir.jl:31
 in cd at file.jl:22
 in cd at pkg/dir.jl:31
 in test at pkg.jl:71
 in process_options at ./client.jl:284
 in _start at ./client.jl:411

>>> End of log
