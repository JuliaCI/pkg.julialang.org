>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.7
INFO: Installing Blosc v0.2.1
INFO: Installing Calculus v0.2.2
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing FileIO v0.2.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.3
INFO: Installing JLD v0.6.11
INFO: Installing LegacyStrings v0.2.2
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.6.0
INFO: Installing Rmath v0.1.7
INFO: Installing SHA v0.3.3
INFO: Installing ScikitLearnBase v0.2.2
INFO: Installing StatsBase v0.12.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date — you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-121-generic #170-Ubuntu SMP Wed Jun 14 09:04:33 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (697.1796875 MB free)
Uptime: 33603.0 sec
Load Avg:  0.93701171875  1.02685546875  1.0400390625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1587352 s       7089 s     121676 s    1332400 s         47 s
#2  3500 MHz    1142054 s        117 s     104896 s    1992544 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.9.1
19 additional packages:
 - BinDeps                       0.4.7
 - Blosc                         0.2.1
 - Calculus                      0.2.2
 - Clustering                    0.7.0
 - Compat                        0.26.0
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - FileIO                        0.2.2
 - HDF5                          0.7.3
 - JLD                           0.6.11
 - LegacyStrings                 0.2.2
 - NearestNeighbors              0.0.5
 - PDMats                        0.6.0
 - Rmath                         0.1.7
 - SHA                           0.3.3
 - ScikitLearnBase               0.2.2
 - StatsBase                     0.12.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-1.9462768721948285e6,[4031.6493636369564,95968.35063636306],
[-554.0094029586271 -6099.270462702745 -6078.686735635246
 697.5001558373206 6001.4697268706195 6262.314242767938],

[
[4083.1206687678373 607.3909821667058 825.064686361602
 607.390982166706 11238.147402031891 7698.389556551914
 825.0646863616021 7698.389556551914 11190.533594696535],

[95976.27549608193 -147.51762808240906 -1279.8525286937781
 -147.51762808240903 88616.21592774444 -7885.287537547976
 -1279.852528693778 -7885.287537547976 88961.7049339537]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.326513e+03
      1       1.054130e+03      -2.723829e+02 |        7
      2       9.343185e+02      -1.198114e+02 |        4
      3       9.052895e+02      -2.902904e+01 |        3
      4       8.963981e+02      -8.891404e+00 |        0
      5       8.963981e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 896.3980787945234)
INFO: K-means with 272 data points using 5 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.064055
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.850334
INFO: iteration 2, lowerbound -3.750363
INFO: iteration 3, lowerbound -3.627921
INFO: iteration 4, lowerbound -3.466787
INFO: iteration 5, lowerbound -3.280873
INFO: iteration 6, lowerbound -3.088697
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -2.900351
INFO: dropping number of Gaussions to 6
INFO: iteration 8, lowerbound -2.715139
INFO: iteration 9, lowerbound -2.565861
INFO: dropping number of Gaussions to 5
INFO: iteration 10, lowerbound -2.464871
INFO: iteration 11, lowerbound -2.407776
INFO: dropping number of Gaussions to 3
INFO: iteration 12, lowerbound -2.359141
INFO: iteration 13, lowerbound -2.324525
INFO: iteration 14, lowerbound -2.309582
INFO: iteration 15, lowerbound -2.308524
INFO: dropping number of Gaussions to 2
INFO: iteration 16, lowerbound -2.302916
INFO: iteration 17, lowerbound -2.299259
INFO: iteration 18, lowerbound -2.299256
INFO: iteration 19, lowerbound -2.299254
INFO: iteration 20, lowerbound -2.299254
INFO: iteration 21, lowerbound -2.299253
INFO: iteration 22, lowerbound -2.299253
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Tue 11 Jul 2017 01:41:57 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Tue 11 Jul 2017 01:41:58 PM UTC: K-means with 272 data points using 5 iterations
11.3 data points per parameter
,Tue 11 Jul 2017 01:41:59 PM UTC: EM with 272 data points 0 iterations avll -2.064055
5.8 data points per parameter
,Tue 11 Jul 2017 01:42:00 PM UTC: GMM converted to Variational GMM
,Tue 11 Jul 2017 01:42:02 PM UTC: iteration 1, lowerbound -3.850334
,Tue 11 Jul 2017 01:42:02 PM UTC: iteration 2, lowerbound -3.750363
,Tue 11 Jul 2017 01:42:02 PM UTC: iteration 3, lowerbound -3.627921
,Tue 11 Jul 2017 01:42:02 PM UTC: iteration 4, lowerbound -3.466787
,Tue 11 Jul 2017 01:42:02 PM UTC: iteration 5, lowerbound -3.280873
,Tue 11 Jul 2017 01:42:02 PM UTC: iteration 6, lowerbound -3.088697
,Tue 11 Jul 2017 01:42:03 PM UTC: dropping number of Gaussions to 7
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 7, lowerbound -2.900351
,Tue 11 Jul 2017 01:42:03 PM UTC: dropping number of Gaussions to 6
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 8, lowerbound -2.715139
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 9, lowerbound -2.565861
,Tue 11 Jul 2017 01:42:03 PM UTC: dropping number of Gaussions to 5
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 10, lowerbound -2.464871
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 11, lowerbound -2.407776
,Tue 11 Jul 2017 01:42:03 PM UTC: dropping number of Gaussions to 3
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 12, lowerbound -2.359141
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 13, lowerbound -2.324525
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 14, lowerbound -2.309582
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 15, lowerbound -2.308524
,Tue 11 Jul 2017 01:42:03 PM UTC: dropping number of Gaussions to 2
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 16, lowerbound -2.302916
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 17, lowerbound -2.299259
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 18, lowerbound -2.299256
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 19, lowerbound -2.299254
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 20, lowerbound -2.299254
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 21, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 22, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 23, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 24, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 25, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 26, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 27, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 28, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 29, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 30, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 31, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 32, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 33, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 34, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 35, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 36, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 37, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 38, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 39, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 40, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 41, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 42, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 43, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 44, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 45, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 46, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 47, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 48, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 49, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: iteration 50, lowerbound -2.299253
,Tue 11 Jul 2017 01:42:03 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601365,95.9549077739863]
β = [178.04509222601365,95.9549077739863]
m = [4.2503007332699125 79.28686694436183
 2.000229257775372 53.85198717246133]
ν = [180.04509222601365,97.9549077739863]
W = [
[0.184041555474849 -0.007644049042327192
 0.0 0.00858170516633336],

[0.3758763611948354 -0.008953123827345985
 0.0 0.012748664777409597]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0084592463804805
avll from llpg:  -1.0084592463804805
avll direct:     -1.0084592463804805
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.979806046732141
avll from llpg:  -0.9798060467321411
avll direct:     -0.9798060467321411
sum posterior: 100000.0
32x26 Array{Float64,2}:
  0.072461    -0.0973048   -0.0953394   …  -0.0748444   -0.158312 
  0.137543     0.16052      0.203225       -0.00452634   0.0283066
  0.12567     -0.088474     0.0100493      -0.111151     0.197492 
  0.09403      0.177668     0.0122623      -0.0196068   -0.0994875
  0.13023      0.0922213   -0.148192       -0.0615094    0.0018392
  0.10929     -0.175834    -0.10322     …   0.0460754   -0.248178 
  0.0265248   -0.0714856    0.00921253     -0.117004     0.0191187
 -0.0546991   -0.00707307   0.0892016      -0.015811     0.111871 
 -0.00496142   0.00988293  -0.163379        0.00416143  -0.164111 
  0.0368882   -0.171788    -0.0657966       0.0136038    0.132955 
  ⋮                                     ⋱                ⋮        
 -0.121996     0.0349911    0.200574       -0.00140407   0.0155373
 -0.0401318   -0.0920954    0.0499111       0.130646    -0.0496773
 -0.133302     0.05554     -0.112976    …  -0.0793126    0.115861 
 -0.0403093   -0.0973808   -0.205903       -0.0790323    0.0591687
 -0.207494     0.0655306   -0.0651909      -0.0342393    0.0904918
  0.0435468    0.0496666   -0.147569        0.166035     0.157653 
 -0.00785741   0.100652    -0.0350091      -0.0125696   -0.200753 
 -0.121754    -0.107578    -0.187204    …   0.0496319   -0.0698474
 -0.146165    -0.0988493   -0.0779477      -0.0091976    0.127629 kind diag, method split
0: avll = -1.3916029622340962
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.391666
INFO: iteration 2, average log likelihood -1.391536
INFO: iteration 3, average log likelihood -1.389508
INFO: iteration 4, average log likelihood -1.374667
INFO: iteration 5, average log likelihood -1.357099
INFO: iteration 6, average log likelihood -1.353926
INFO: iteration 7, average log likelihood -1.353278
INFO: iteration 8, average log likelihood -1.353009
INFO: iteration 9, average log likelihood -1.352866
INFO: iteration 10, average log likelihood -1.352775
INFO: iteration 11, average log likelihood -1.352709
INFO: iteration 12, average log likelihood -1.352653
INFO: iteration 13, average log likelihood -1.352600
INFO: iteration 14, average log likelihood -1.352543
INFO: iteration 15, average log likelihood -1.352481
INFO: iteration 16, average log likelihood -1.352413
INFO: iteration 17, average log likelihood -1.352343
INFO: iteration 18, average log likelihood -1.352272
INFO: iteration 19, average log likelihood -1.352197
INFO: iteration 20, average log likelihood -1.352118
INFO: iteration 21, average log likelihood -1.352030
INFO: iteration 22, average log likelihood -1.351917
INFO: iteration 23, average log likelihood -1.351737
INFO: iteration 24, average log likelihood -1.351367
INFO: iteration 25, average log likelihood -1.350551
INFO: iteration 26, average log likelihood -1.349562
INFO: iteration 27, average log likelihood -1.348874
INFO: iteration 28, average log likelihood -1.348524
INFO: iteration 29, average log likelihood -1.348367
INFO: iteration 30, average log likelihood -1.348292
INFO: iteration 31, average log likelihood -1.348254
INFO: iteration 32, average log likelihood -1.348231
INFO: iteration 33, average log likelihood -1.348215
INFO: iteration 34, average log likelihood -1.348201
INFO: iteration 35, average log likelihood -1.348187
INFO: iteration 36, average log likelihood -1.348171
INFO: iteration 37, average log likelihood -1.348152
INFO: iteration 38, average log likelihood -1.348126
INFO: iteration 39, average log likelihood -1.348090
INFO: iteration 40, average log likelihood -1.348039
INFO: iteration 41, average log likelihood -1.347972
INFO: iteration 42, average log likelihood -1.347895
INFO: iteration 43, average log likelihood -1.347818
INFO: iteration 44, average log likelihood -1.347749
INFO: iteration 45, average log likelihood -1.347692
INFO: iteration 46, average log likelihood -1.347643
INFO: iteration 47, average log likelihood -1.347597
INFO: iteration 48, average log likelihood -1.347551
INFO: iteration 49, average log likelihood -1.347498
INFO: iteration 50, average log likelihood -1.347428
INFO: EM with 100000 data points 50 iterations avll -1.347428
952.4 data points per parameter
1: avll = [-1.3916664173786188,-1.3915364598206066,-1.3895082702679786,-1.37466651477733,-1.3570988260093715,-1.3539262139565953,-1.353277840762759,-1.353008606857795,-1.352865598849908,-1.3527749024160773,-1.3527085459918458,-1.3526531446315817,-1.3526001375405985,-1.3525433180685305,-1.3524809466086212,-1.3524132903763881,-1.3523431556915326,-1.3522715664146137,-1.3521967421330838,-1.3521176634621832,-1.3520299301428016,-1.351917379748687,-1.3517373560367214,-1.3513669854483839,-1.3505514381910069,-1.349561717362732,-1.348873650485491,-1.3485242650166078,-1.3483672477126956,-1.3482924282957602,-1.3482537842057365,-1.34823094199088,-1.3482147436005454,-1.3482007385923303,-1.3481865095403704,-1.3481705667802626,-1.348151513789207,-1.3481263334462763,-1.348090294005064,-1.3480389438682905,-1.3479719048845684,-1.347894690586319,-1.3478178243160641,-1.347749302846965,-1.3476916922166273,-1.347642623289266,-1.347597426022654,-1.347551295809519,-1.347497669604731,-1.347427821065952]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.347444
INFO: iteration 2, average log likelihood -1.347140
INFO: iteration 3, average log likelihood -1.345880
INFO: iteration 4, average log likelihood -1.336169
INFO: iteration 5, average log likelihood -1.317465
INFO: iteration 6, average log likelihood -1.308312
INFO: iteration 7, average log likelihood -1.304999
INFO: iteration 8, average log likelihood -1.303220
INFO: iteration 9, average log likelihood -1.301990
INFO: iteration 10, average log likelihood -1.300990
INFO: iteration 11, average log likelihood -1.300053
INFO: iteration 12, average log likelihood -1.299024
INFO: iteration 13, average log likelihood -1.297963
INFO: iteration 14, average log likelihood -1.297195
INFO: iteration 15, average log likelihood -1.296649
INFO: iteration 16, average log likelihood -1.296186
INFO: iteration 17, average log likelihood -1.295780
INFO: iteration 18, average log likelihood -1.295421
INFO: iteration 19, average log likelihood -1.295097
INFO: iteration 20, average log likelihood -1.294827
INFO: iteration 21, average log likelihood -1.294624
INFO: iteration 22, average log likelihood -1.294485
INFO: iteration 23, average log likelihood -1.294388
INFO: iteration 24, average log likelihood -1.294318
INFO: iteration 25, average log likelihood -1.294267
INFO: iteration 26, average log likelihood -1.294229
INFO: iteration 27, average log likelihood -1.294201
INFO: iteration 28, average log likelihood -1.294178
INFO: iteration 29, average log likelihood -1.294160
INFO: iteration 30, average log likelihood -1.294146
INFO: iteration 31, average log likelihood -1.294134
INFO: iteration 32, average log likelihood -1.294124
INFO: iteration 33, average log likelihood -1.294117
INFO: iteration 34, average log likelihood -1.294111
INFO: iteration 35, average log likelihood -1.294106
INFO: iteration 36, average log likelihood -1.294103
INFO: iteration 37, average log likelihood -1.294101
INFO: iteration 38, average log likelihood -1.294099
INFO: iteration 39, average log likelihood -1.294097
INFO: iteration 40, average log likelihood -1.294096
INFO: iteration 41, average log likelihood -1.294095
INFO: iteration 42, average log likelihood -1.294095
INFO: iteration 43, average log likelihood -1.294094
INFO: iteration 44, average log likelihood -1.294094
INFO: iteration 45, average log likelihood -1.294094
INFO: iteration 46, average log likelihood -1.294094
INFO: iteration 47, average log likelihood -1.294094
INFO: iteration 48, average log likelihood -1.294093
INFO: iteration 49, average log likelihood -1.294093
INFO: iteration 50, average log likelihood -1.294093
INFO: EM with 100000 data points 50 iterations avll -1.294093
473.9 data points per parameter
2: avll = [-1.3474441029685618,-1.3471404907950049,-1.3458800680682557,-1.336168526229461,-1.3174648964546678,-1.308311796220471,-1.3049994311673596,-1.303220125645063,-1.301990048278231,-1.3009896728086952,-1.3000530615802488,-1.2990239177682952,-1.297963125065768,-1.2971946659034341,-1.2966492646596537,-1.2961859328203928,-1.2957798603426218,-1.2954205893722028,-1.2950965278921764,-1.2948265266838022,-1.2946241669543646,-1.2944845970916794,-1.2943878874644996,-1.2943183060148975,-1.2942673267383842,-1.294229354277567,-1.2942006016677705,-1.2941782111962832,-1.2941602726787862,-1.2941457113605008,-1.294133869847656,-1.2941243536896574,-1.2941168354422008,-1.2941109877737131,-1.2941064944529053,-1.2941030777401386,-1.2941005072919487,-1.2940985932743796,-1.2940971798548526,-1.2940961415861671,-1.2940953802942283,-1.2940948212977708,-1.2940944091221933,-1.2940941032795337,-1.29409387455889,-1.2940937020166983,-1.2940935706650427,-1.2940934697604325,-1.2940933915676354,-1.2940933304805327]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.294242
INFO: iteration 2, average log likelihood -1.294084
INFO: iteration 3, average log likelihood -1.293294
INFO: iteration 4, average log likelihood -1.285244
INFO: iteration 5, average log likelihood -1.263961
INFO: iteration 6, average log likelihood -1.250240
INFO: iteration 7, average log likelihood -1.245218
INFO: iteration 8, average log likelihood -1.242934
INFO: iteration 9, average log likelihood -1.241580
INFO: iteration 10, average log likelihood -1.240597
INFO: iteration 11, average log likelihood -1.239782
INFO: iteration 12, average log likelihood -1.239024
INFO: iteration 13, average log likelihood -1.238257
INFO: iteration 14, average log likelihood -1.237493
INFO: iteration 15, average log likelihood -1.236722
INFO: iteration 16, average log likelihood -1.235940
INFO: iteration 17, average log likelihood -1.235159
INFO: iteration 18, average log likelihood -1.234354
INFO: iteration 19, average log likelihood -1.233593
INFO: iteration 20, average log likelihood -1.233058
INFO: iteration 21, average log likelihood -1.232748
INFO: iteration 22, average log likelihood -1.232548
INFO: iteration 23, average log likelihood -1.232410
INFO: iteration 24, average log likelihood -1.232291
INFO: iteration 25, average log likelihood -1.232138
INFO: iteration 26, average log likelihood -1.231902
INFO: iteration 27, average log likelihood -1.231533
INFO: iteration 28, average log likelihood -1.230994
INFO: iteration 29, average log likelihood -1.230359
INFO: iteration 30, average log likelihood -1.229808
INFO: iteration 31, average log likelihood -1.229484
INFO: iteration 32, average log likelihood -1.229368
INFO: iteration 33, average log likelihood -1.229329
INFO: iteration 34, average log likelihood -1.229311
INFO: iteration 35, average log likelihood -1.229300
INFO: iteration 36, average log likelihood -1.229292
INFO: iteration 37, average log likelihood -1.229284
INFO: iteration 38, average log likelihood -1.229275
INFO: iteration 39, average log likelihood -1.229266
INFO: iteration 40, average log likelihood -1.229255
INFO: iteration 41, average log likelihood -1.229241
INFO: iteration 42, average log likelihood -1.229225
INFO: iteration 43, average log likelihood -1.229203
INFO: iteration 44, average log likelihood -1.229175
INFO: iteration 45, average log likelihood -1.229137
INFO: iteration 46, average log likelihood -1.229085
INFO: iteration 47, average log likelihood -1.229007
INFO: iteration 48, average log likelihood -1.228888
INFO: iteration 49, average log likelihood -1.228699
INFO: iteration 50, average log likelihood -1.228401
INFO: EM with 100000 data points 50 iterations avll -1.228401
236.4 data points per parameter
3: avll = [-1.2942420091110038,-1.2940836114507512,-1.293294448436376,-1.2852439100002206,-1.263961380902643,-1.2502398210391967,-1.2452180380534912,-1.2429340256791677,-1.2415797093689334,-1.240596571773087,-1.2397821847596036,-1.2390239677240724,-1.2382572729713972,-1.2374930691464539,-1.2367219555618763,-1.2359395895539043,-1.2351594566817883,-1.2343536873506158,-1.2335927466788794,-1.2330582698979433,-1.2327475128188894,-1.232548075939159,-1.2324102526367835,-1.2322906072293884,-1.2321382415939621,-1.2319020192092012,-1.2315330334474996,-1.2309937526586165,-1.2303592173244937,-1.2298075636898984,-1.2294840897435029,-1.2293683285997246,-1.2293289331381578,-1.2293112178604115,-1.2293003614032796,-1.229291785982197,-1.2292837133922176,-1.2292752610931919,-1.2292658204738316,-1.2292547872558175,-1.2292413974257115,-1.2292246268684761,-1.2292031070207141,-1.2291749610782199,-1.2291373330444897,-1.2290847577453454,-1.2290069402880235,-1.22888766478317,-1.2286987538306433,-1.2284012173712808]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.228171
INFO: iteration 2, average log likelihood -1.227368
INFO: iteration 3, average log likelihood -1.224732
INFO: iteration 4, average log likelihood -1.203136
WARNING: Variances had to be floored 13
INFO: iteration 5, average log likelihood -1.161528
INFO: iteration 6, average log likelihood -1.148154
WARNING: Variances had to be floored 13 14
INFO: iteration 7, average log likelihood -1.133765
INFO: iteration 8, average log likelihood -1.141527
WARNING: Variances had to be floored 13
INFO: iteration 9, average log likelihood -1.132411
WARNING: Variances had to be floored 14
INFO: iteration 10, average log likelihood -1.131792
WARNING: Variances had to be floored 13 16
INFO: iteration 11, average log likelihood -1.131535
INFO: iteration 12, average log likelihood -1.137103
WARNING: Variances had to be floored 13 14
INFO: iteration 13, average log likelihood -1.120412
INFO: iteration 14, average log likelihood -1.134578
WARNING: Variances had to be floored 13
INFO: iteration 15, average log likelihood -1.125842
WARNING: Variances had to be floored 14
INFO: iteration 16, average log likelihood -1.125639
WARNING: Variances had to be floored 13
INFO: iteration 17, average log likelihood -1.125877
INFO: iteration 18, average log likelihood -1.126208
WARNING: Variances had to be floored 13 14
INFO: iteration 19, average log likelihood -1.115927
INFO: iteration 20, average log likelihood -1.131775
WARNING: Variances had to be floored 13
INFO: iteration 21, average log likelihood -1.123865
WARNING: Variances had to be floored 14
INFO: iteration 22, average log likelihood -1.124401
WARNING: Variances had to be floored 13
INFO: iteration 23, average log likelihood -1.125294
INFO: iteration 24, average log likelihood -1.125840
WARNING: Variances had to be floored 13 14
INFO: iteration 25, average log likelihood -1.115829
INFO: iteration 26, average log likelihood -1.131621
WARNING: Variances had to be floored 13
INFO: iteration 27, average log likelihood -1.123774
WARNING: Variances had to be floored 14
INFO: iteration 28, average log likelihood -1.124346
WARNING: Variances had to be floored 13
INFO: iteration 29, average log likelihood -1.125277
INFO: iteration 30, average log likelihood -1.125806
WARNING: Variances had to be floored 13 14
INFO: iteration 31, average log likelihood -1.115845
INFO: iteration 32, average log likelihood -1.131605
WARNING: Variances had to be floored 13
INFO: iteration 33, average log likelihood -1.123766
WARNING: Variances had to be floored 14
INFO: iteration 34, average log likelihood -1.124344
WARNING: Variances had to be floored 13
INFO: iteration 35, average log likelihood -1.125279
INFO: iteration 36, average log likelihood -1.125801
WARNING: Variances had to be floored 13 14
INFO: iteration 37, average log likelihood -1.115852
INFO: iteration 38, average log likelihood -1.131602
WARNING: Variances had to be floored 13
INFO: iteration 39, average log likelihood -1.123764
WARNING: Variances had to be floored 14
INFO: iteration 40, average log likelihood -1.124344
WARNING: Variances had to be floored 13
INFO: iteration 41, average log likelihood -1.125280
INFO: iteration 42, average log likelihood -1.125800
WARNING: Variances had to be floored 13 14
INFO: iteration 43, average log likelihood -1.115855
INFO: iteration 44, average log likelihood -1.131602
WARNING: Variances had to be floored 13
INFO: iteration 45, average log likelihood -1.123764
WARNING: Variances had to be floored 14
INFO: iteration 46, average log likelihood -1.124345
WARNING: Variances had to be floored 13
INFO: iteration 47, average log likelihood -1.125281
INFO: iteration 48, average log likelihood -1.125799
WARNING: Variances had to be floored 13 14
INFO: iteration 49, average log likelihood -1.115856
INFO: iteration 50, average log likelihood -1.131602
INFO: EM with 100000 data points 50 iterations avll -1.131602
118.1 data points per parameter
4: avll = [-1.2281710868229148,-1.227367730421217,-1.2247315491065445,-1.2031357935609996,-1.1615275583056186,-1.1481542223333268,-1.1337654745662724,-1.1415272043129414,-1.1324107843367919,-1.1317922713995643,-1.1315347598885084,-1.1371029234230736,-1.1204124557838044,-1.1345779550697117,-1.1258423698725315,-1.125638973776466,-1.1258766891216998,-1.1262078777151125,-1.1159265741843518,-1.1317749492788243,-1.123865336384071,-1.1244014679486594,-1.1252935073904733,-1.1258404300858456,-1.115829231730676,-1.1316211401569503,-1.1237740608468851,-1.1243457035968538,-1.1252765479846412,-1.1258063419081648,-1.1158447991430314,-1.1316054112952518,-1.1237660087385022,-1.1243435778300117,-1.1252791078475735,-1.1258010827345588,-1.1158518838616334,-1.1316024879480846,-1.123764354370648,-1.124344045996584,-1.1252802500202113,-1.1257997254435053,-1.1158546584062436,-1.13160178356988,-1.1237639353300626,-1.1243445876167049,-1.1252808597797885,-1.125799324015192,-1.1158559946023419,-1.1316016014243702]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 25 26
INFO: iteration 1, average log likelihood -1.123981
WARNING: Variances had to be floored 25 26 27 28
INFO: iteration 2, average log likelihood -1.119987
WARNING: Variances had to be floored 25 26
INFO: iteration 3, average log likelihood -1.122162
WARNING: Variances had to be floored 12 25 26 27 28
INFO: iteration 4, average log likelihood -1.097390
WARNING: Variances had to be floored 12 25 26 32
INFO: iteration 5, average log likelihood -1.041413
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28
INFO: iteration 6, average log likelihood -0.993544
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 7, average log likelihood -1.022626
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 8, average log likelihood -0.993909
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 9, average log likelihood -0.984623
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 10, average log likelihood -1.012520
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 11, average log likelihood -1.001277
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 12, average log likelihood -0.974419
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 13, average log likelihood -1.020430
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 14, average log likelihood -0.992891
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 15, average log likelihood -0.982125
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 16, average log likelihood -1.012107
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 17, average log likelihood -1.000675
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 18, average log likelihood -0.973635
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 19, average log likelihood -1.020191
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 20, average log likelihood -0.992713
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 21, average log likelihood -0.981750
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 22, average log likelihood -1.012064
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 23, average log likelihood -1.000591
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 24, average log likelihood -0.973520
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 25, average log likelihood -1.020158
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 26, average log likelihood -0.992686
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 27, average log likelihood -0.981702
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 28, average log likelihood -1.012053
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 29, average log likelihood -1.000578
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 30, average log likelihood -0.973501
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 31, average log likelihood -1.020151
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 32, average log likelihood -0.992675
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 33, average log likelihood -0.981690
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 34, average log likelihood -1.012045
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 35, average log likelihood -1.000572
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 36, average log likelihood -0.973492
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 37, average log likelihood -1.020147
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 38, average log likelihood -0.992666
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 39, average log likelihood -0.981682
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 40, average log likelihood -1.012039
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 41, average log likelihood -1.000568
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 42, average log likelihood -0.973485
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 43, average log likelihood -1.020145
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 44, average log likelihood -0.992658
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 45, average log likelihood -0.981676
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 46, average log likelihood -1.012035
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 47, average log likelihood -1.000564
WARNING: Variances had to be floored 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 48, average log likelihood -0.973478
WARNING: Variances had to be floored 6 12 25 26
INFO: iteration 49, average log likelihood -1.020143
WARNING: Variances had to be floored 11 12 25 26 27 28 32
INFO: iteration 50, average log likelihood -0.992650
INFO: EM with 100000 data points 50 iterations avll -0.992650
59.0 data points per parameter
5: avll = [-1.1239811259332497,-1.1199871269799502,-1.1221621110452296,-1.0973900808063648,-1.0414128504270415,-0.9935435621384938,-1.0226255206996024,-0.9939086365368536,-0.984623159566176,-1.0125196367611757,-1.0012772185900805,-0.9744193627845655,-1.0204300251050447,-0.9928907499881493,-0.982124833090704,-1.0121074123757818,-1.0006749827911676,-0.9736345050800096,-1.0201905717686541,-0.9927130060033722,-0.9817498313930398,-1.0120635748845739,-1.0005911415442816,-0.9735197496432646,-1.0201582086003607,-0.9926856386729745,-0.9817016432617172,-1.0120525978934996,-1.0005782465709328,-0.9735012478407921,-1.0201511932370266,-0.9926745562415767,-0.9816898803833425,-1.0120449093595345,-1.0005723338874448,-0.9734918283504932,-1.0201474710628435,-0.9926656262210164,-0.9816819863596211,-1.0120393161138772,-1.0005678831294784,-0.9734847558801546,-1.0201449387721933,-0.9926579914254327,-0.9816755336897677,-1.0120350363252586,-1.0005637330795671,-0.973478403519719,-1.0201430747541393,-0.9926504759086148]
[-1.3916029622340962,-1.3916664173786188,-1.3915364598206066,-1.3895082702679786,-1.37466651477733,-1.3570988260093715,-1.3539262139565953,-1.353277840762759,-1.353008606857795,-1.352865598849908,-1.3527749024160773,-1.3527085459918458,-1.3526531446315817,-1.3526001375405985,-1.3525433180685305,-1.3524809466086212,-1.3524132903763881,-1.3523431556915326,-1.3522715664146137,-1.3521967421330838,-1.3521176634621832,-1.3520299301428016,-1.351917379748687,-1.3517373560367214,-1.3513669854483839,-1.3505514381910069,-1.349561717362732,-1.348873650485491,-1.3485242650166078,-1.3483672477126956,-1.3482924282957602,-1.3482537842057365,-1.34823094199088,-1.3482147436005454,-1.3482007385923303,-1.3481865095403704,-1.3481705667802626,-1.348151513789207,-1.3481263334462763,-1.348090294005064,-1.3480389438682905,-1.3479719048845684,-1.347894690586319,-1.3478178243160641,-1.347749302846965,-1.3476916922166273,-1.347642623289266,-1.347597426022654,-1.347551295809519,-1.347497669604731,-1.347427821065952,-1.3474441029685618,-1.3471404907950049,-1.3458800680682557,-1.336168526229461,-1.3174648964546678,-1.308311796220471,-1.3049994311673596,-1.303220125645063,-1.301990048278231,-1.3009896728086952,-1.3000530615802488,-1.2990239177682952,-1.297963125065768,-1.2971946659034341,-1.2966492646596537,-1.2961859328203928,-1.2957798603426218,-1.2954205893722028,-1.2950965278921764,-1.2948265266838022,-1.2946241669543646,-1.2944845970916794,-1.2943878874644996,-1.2943183060148975,-1.2942673267383842,-1.294229354277567,-1.2942006016677705,-1.2941782111962832,-1.2941602726787862,-1.2941457113605008,-1.294133869847656,-1.2941243536896574,-1.2941168354422008,-1.2941109877737131,-1.2941064944529053,-1.2941030777401386,-1.2941005072919487,-1.2940985932743796,-1.2940971798548526,-1.2940961415861671,-1.2940953802942283,-1.2940948212977708,-1.2940944091221933,-1.2940941032795337,-1.29409387455889,-1.2940937020166983,-1.2940935706650427,-1.2940934697604325,-1.2940933915676354,-1.2940933304805327,-1.2942420091110038,-1.2940836114507512,-1.293294448436376,-1.2852439100002206,-1.263961380902643,-1.2502398210391967,-1.2452180380534912,-1.2429340256791677,-1.2415797093689334,-1.240596571773087,-1.2397821847596036,-1.2390239677240724,-1.2382572729713972,-1.2374930691464539,-1.2367219555618763,-1.2359395895539043,-1.2351594566817883,-1.2343536873506158,-1.2335927466788794,-1.2330582698979433,-1.2327475128188894,-1.232548075939159,-1.2324102526367835,-1.2322906072293884,-1.2321382415939621,-1.2319020192092012,-1.2315330334474996,-1.2309937526586165,-1.2303592173244937,-1.2298075636898984,-1.2294840897435029,-1.2293683285997246,-1.2293289331381578,-1.2293112178604115,-1.2293003614032796,-1.229291785982197,-1.2292837133922176,-1.2292752610931919,-1.2292658204738316,-1.2292547872558175,-1.2292413974257115,-1.2292246268684761,-1.2292031070207141,-1.2291749610782199,-1.2291373330444897,-1.2290847577453454,-1.2290069402880235,-1.22888766478317,-1.2286987538306433,-1.2284012173712808,-1.2281710868229148,-1.227367730421217,-1.2247315491065445,-1.2031357935609996,-1.1615275583056186,-1.1481542223333268,-1.1337654745662724,-1.1415272043129414,-1.1324107843367919,-1.1317922713995643,-1.1315347598885084,-1.1371029234230736,-1.1204124557838044,-1.1345779550697117,-1.1258423698725315,-1.125638973776466,-1.1258766891216998,-1.1262078777151125,-1.1159265741843518,-1.1317749492788243,-1.123865336384071,-1.1244014679486594,-1.1252935073904733,-1.1258404300858456,-1.115829231730676,-1.1316211401569503,-1.1237740608468851,-1.1243457035968538,-1.1252765479846412,-1.1258063419081648,-1.1158447991430314,-1.1316054112952518,-1.1237660087385022,-1.1243435778300117,-1.1252791078475735,-1.1258010827345588,-1.1158518838616334,-1.1316024879480846,-1.123764354370648,-1.124344045996584,-1.1252802500202113,-1.1257997254435053,-1.1158546584062436,-1.13160178356988,-1.1237639353300626,-1.1243445876167049,-1.1252808597797885,-1.125799324015192,-1.1158559946023419,-1.1316016014243702,-1.1239811259332497,-1.1199871269799502,-1.1221621110452296,-1.0973900808063648,-1.0414128504270415,-0.9935435621384938,-1.0226255206996024,-0.9939086365368536,-0.984623159566176,-1.0125196367611757,-1.0012772185900805,-0.9744193627845655,-1.0204300251050447,-0.9928907499881493,-0.982124833090704,-1.0121074123757818,-1.0006749827911676,-0.9736345050800096,-1.0201905717686541,-0.9927130060033722,-0.9817498313930398,-1.0120635748845739,-1.0005911415442816,-0.9735197496432646,-1.0201582086003607,-0.9926856386729745,-0.9817016432617172,-1.0120525978934996,-1.0005782465709328,-0.9735012478407921,-1.0201511932370266,-0.9926745562415767,-0.9816898803833425,-1.0120449093595345,-1.0005723338874448,-0.9734918283504932,-1.0201474710628435,-0.9926656262210164,-0.9816819863596211,-1.0120393161138772,-1.0005678831294784,-0.9734847558801546,-1.0201449387721933,-0.9926579914254327,-0.9816755336897677,-1.0120350363252586,-1.0005637330795671,-0.973478403519719,-1.0201430747541393,-0.9926504759086148]
32x26 Array{Float64,2}:
 -0.061656   -0.0292572   -0.254709    …   0.0411954    0.0340185  -0.0766376
 -0.179879   -0.192594    -0.0976882       0.0387392    0.104815   -0.0934557
  0.0494435  -0.0541052    0.00452416     -0.0887404    0.0139344   0.0154103
  0.180057    0.136627     0.100774        0.140323     0.0690823  -0.208246 
  0.109846   -0.0128273   -0.0987933      -0.160389    -0.0606264   0.164703 
  0.0723655   0.0263844   -0.075595    …   0.0834125    0.0467884   0.0769575
 -0.125114    0.0791763    0.068403        0.165385     0.0894087   0.0439486
 -0.041026    0.0159293    0.0550438       0.048811     0.0302596   0.116278 
  0.0115851   0.0188383    0.0190409      -0.0111507   -0.0473241   0.0454054
 -0.0381822  -0.0155729    0.0761594      -0.0415915   -0.094859    0.0791357
  ⋮                                    ⋱                            ⋮        
  0.0833482   0.18668      0.0280213       0.0733295   -0.0188663  -0.113178 
  0.157163   -0.16476      0.27193         0.105285    -0.106556    0.232908 
  0.0996676  -0.00509752  -0.223212    …   0.312356    -0.109531    0.154208 
 -0.0328757   0.0882345   -0.0825812       0.00552962   0.060696   -0.212591 
  0.0251089   0.10463     -0.039135        0.00250868  -0.0963079  -0.201109 
  0.0533001   0.0110828   -0.0317953       0.0480141    0.146271   -0.0104186
  0.0206261  -0.0520751   -0.0677578       0.0219377    0.0459232  -0.140833 
  0.0511907  -0.0938109   -0.0957523   …  -0.0298178   -0.041913    0.111963 
  0.088852   -0.0641517   -0.11287         0.0585478   -0.0656932  -0.155935 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 1, average log likelihood -0.981670
WARNING: Variances had to be floored 6 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 2, average log likelihood -0.964985
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 3, average log likelihood -0.981617
WARNING: Variances had to be floored 6 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 4, average log likelihood -0.964922
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 5, average log likelihood -0.981615
WARNING: Variances had to be floored 6 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 6, average log likelihood -0.964914
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 7, average log likelihood -0.981614
WARNING: Variances had to be floored 6 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 8, average log likelihood -0.964911
WARNING: Variances had to be floored 6 7 12 13 14 19 25 26
INFO: iteration 9, average log likelihood -0.981614
WARNING: Variances had to be floored 6 7 11 12 13 14 19 25 26 27 28 32
INFO: iteration 10, average log likelihood -0.964909
INFO: EM with 100000 data points 10 iterations avll -0.964909
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.299966e+05
      1       6.598806e+05      -1.701160e+05 |       32
      2       6.282606e+05      -3.161999e+04 |       32
      3       6.120177e+05      -1.624290e+04 |       32
      4       6.046613e+05      -7.356414e+03 |       32
      5       6.010203e+05      -3.641017e+03 |       32
      6       5.987408e+05      -2.279524e+03 |       32
      7       5.970068e+05      -1.733953e+03 |       32
      8       5.955849e+05      -1.421970e+03 |       32
      9       5.943977e+05      -1.187165e+03 |       32
     10       5.935948e+05      -8.029087e+02 |       32
     11       5.929230e+05      -6.717963e+02 |       32
     12       5.921191e+05      -8.039126e+02 |       32
     13       5.910591e+05      -1.060009e+03 |       32
     14       5.899821e+05      -1.076952e+03 |       32
     15       5.890098e+05      -9.723026e+02 |       32
     16       5.882436e+05      -7.661816e+02 |       32
     17       5.876770e+05      -5.666315e+02 |       32
     18       5.872143e+05      -4.627049e+02 |       32
     19       5.869032e+05      -3.110774e+02 |       31
     20       5.867021e+05      -2.010706e+02 |       32
     21       5.865736e+05      -1.285401e+02 |       32
     22       5.864895e+05      -8.411377e+01 |       31
     23       5.864320e+05      -5.748467e+01 |       31
     24       5.863890e+05      -4.301300e+01 |       31
     25       5.863547e+05      -3.430601e+01 |       31
     26       5.863298e+05      -2.486535e+01 |       30
     27       5.863099e+05      -1.989543e+01 |       30
     28       5.862937e+05      -1.621833e+01 |       29
     29       5.862737e+05      -2.000686e+01 |       32
     30       5.862512e+05      -2.247611e+01 |       32
     31       5.862298e+05      -2.146687e+01 |       32
     32       5.862070e+05      -2.273927e+01 |       31
     33       5.861736e+05      -3.339613e+01 |       31
     34       5.861333e+05      -4.034012e+01 |       32
     35       5.860845e+05      -4.879853e+01 |       32
     36       5.860216e+05      -6.291750e+01 |       32
     37       5.859493e+05      -7.227011e+01 |       32
     38       5.858677e+05      -8.158780e+01 |       32
     39       5.857743e+05      -9.339827e+01 |       30
     40       5.856643e+05      -1.099790e+02 |       32
     41       5.855240e+05      -1.403318e+02 |       32
     42       5.853751e+05      -1.488636e+02 |       32
     43       5.852401e+05      -1.350732e+02 |       32
     44       5.851471e+05      -9.295972e+01 |       32
     45       5.850977e+05      -4.940115e+01 |       31
     46       5.850643e+05      -3.342937e+01 |       31
     47       5.850453e+05      -1.900180e+01 |       30
     48       5.850336e+05      -1.166000e+01 |       29
     49       5.850235e+05      -1.016131e+01 |       30
     50       5.850103e+05      -1.313513e+01 |       26
K-means terminated without convergence after 50 iterations (objv = 585010.318347487)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.290541
INFO: iteration 2, average log likelihood -1.247993
INFO: iteration 3, average log likelihood -1.206000
INFO: iteration 4, average log likelihood -1.163692
WARNING: Variances had to be floored 22 30
INFO: iteration 5, average log likelihood -1.109590
WARNING: Variances had to be floored 3 6 23 26
INFO: iteration 6, average log likelihood -1.059107
WARNING: Variances had to be floored 11 14 18 20 28
INFO: iteration 7, average log likelihood -1.053816
WARNING: Variances had to be floored 2 32
INFO: iteration 8, average log likelihood -1.076559
WARNING: Variances had to be floored 22
INFO: iteration 9, average log likelihood -1.040115
WARNING: Variances had to be floored 6 18 20 23 26 30
INFO: iteration 10, average log likelihood -0.979572
WARNING: Variances had to be floored 11 32
INFO: iteration 11, average log likelihood -1.034609
WARNING: Variances had to be floored 2 7 21 24
INFO: iteration 12, average log likelihood -1.000004
WARNING: Variances had to be floored 22 26 28
INFO: iteration 13, average log likelihood -1.007229
WARNING: Variances had to be floored 6 18 20 23 30 32
INFO: iteration 14, average log likelihood -0.992099
WARNING: Variances had to be floored 2 14
INFO: iteration 15, average log likelihood -1.036022
WARNING: Variances had to be floored 7 21 26
INFO: iteration 16, average log likelihood -1.004500
WARNING: Variances had to be floored 6 11 18 20 24 28
INFO: iteration 17, average log likelihood -0.986198
WARNING: Variances had to be floored 23 30 32
INFO: iteration 18, average log likelihood -1.028764
WARNING: Variances had to be floored 2 14 22 26
INFO: iteration 19, average log likelihood -1.019660
WARNING: Variances had to be floored 6 7 11 21
INFO: iteration 20, average log likelihood -1.017044
WARNING: Variances had to be floored 18 20 24 32
INFO: iteration 21, average log likelihood -0.996573
WARNING: Variances had to be floored 23 26 30
INFO: iteration 22, average log likelihood -1.014225
WARNING: Variances had to be floored 2 14 28
INFO: iteration 23, average log likelihood -1.021067
WARNING: Variances had to be floored 6 7
INFO: iteration 24, average log likelihood -1.002257
WARNING: Variances had to be floored 11 18 20 21 26 32
INFO: iteration 25, average log likelihood -0.980611
WARNING: Variances had to be floored 22 23 24 30
INFO: iteration 26, average log likelihood -1.032458
WARNING: Variances had to be floored 2 6 14
INFO: iteration 27, average log likelihood -1.019513
WARNING: Variances had to be floored 7 20 26
INFO: iteration 28, average log likelihood -1.003368
WARNING: Variances had to be floored 11 18 28 32
INFO: iteration 29, average log likelihood -1.006168
WARNING: Variances had to be floored 6 23 24 30
INFO: iteration 30, average log likelihood -1.016802
WARNING: Variances had to be floored 2 20 26
INFO: iteration 31, average log likelihood -1.013809
WARNING: Variances had to be floored 7 14 21
INFO: iteration 32, average log likelihood -1.008334
WARNING: Variances had to be floored 6 11 18 28 32
INFO: iteration 33, average log likelihood -0.988015
WARNING: Variances had to be floored 20 23 24 26 30
INFO: iteration 34, average log likelihood -1.022841
WARNING: Variances had to be floored 2 22
INFO: iteration 35, average log likelihood -1.032457
WARNING: Variances had to be floored 6 7
INFO: iteration 36, average log likelihood -0.994603
WARNING: Variances had to be floored 11 14 18 20 26 28 30 32
INFO: iteration 37, average log likelihood -0.968024
WARNING: Variances had to be floored 2 21 23 24
INFO: iteration 38, average log likelihood -1.048589
WARNING: Variances had to be floored 6 22
INFO: iteration 39, average log likelihood -1.024012
WARNING: Variances had to be floored 7 11 20 26
INFO: iteration 40, average log likelihood -0.995122
WARNING: Variances had to be floored 2 18 21 30 32
INFO: iteration 41, average log likelihood -1.007956
WARNING: Variances had to be floored 6 23 24
INFO: iteration 42, average log likelihood -1.005065
WARNING: Variances had to be floored 14 22 26 28
INFO: iteration 43, average log likelihood -0.996038
WARNING: Variances had to be floored 7 20 30
INFO: iteration 44, average log likelihood -1.016201
WARNING: Variances had to be floored 11 18 21
INFO: iteration 45, average log likelihood -0.996652
WARNING: Variances had to be floored 2 6 22 23 24 26
INFO: iteration 46, average log likelihood -0.973855
WARNING: Variances had to be floored 20 28 32
INFO: iteration 47, average log likelihood -1.023482
WARNING: Variances had to be floored 7 11
INFO: iteration 48, average log likelihood -1.019666
WARNING: Variances had to be floored 2 14 18 26 30
INFO: iteration 49, average log likelihood -0.988170
WARNING: Variances had to be floored 6 20 22 23 24
INFO: iteration 50, average log likelihood -1.006188
INFO: EM with 100000 data points 50 iterations avll -1.006188
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.0325913   -0.0748507    0.00811847  …  -0.109308     0.0367684 
  0.0129996   -0.0325582   -0.150196        0.00202374  -0.154097  
 -0.0966765   -0.102826    -0.204571       -0.082965     0.0589807 
 -0.159518     0.0430203   -0.125461       -0.080035     0.11069   
  0.0528412    0.00506733  -0.039147        0.145562    -0.0165225 
 -0.109609     0.03132     -0.0544242   …  -0.0835712   -0.228392  
  0.0190112   -0.161614    -0.0668086       0.00197395   0.127391  
  0.195474     0.00692577   0.0214502      -0.0567555    0.133554  
  0.0399738    0.0390836   -0.148315        0.136551     0.149655  
  0.182766     0.136712     0.101036        0.0697203   -0.212975  
  ⋮                                     ⋱                ⋮         
  0.139508     0.058224    -0.142062       -0.0589887    0.00206361
  0.140207     0.125727     0.209269       -0.00539931   0.0322966 
 -0.109015     0.0949287    0.0833403   …   0.0858087    0.0288655 
 -0.0120842    0.0016617    0.045787       -0.0666863    0.0624391 
  0.105249    -0.178376    -0.122425        0.0535429   -0.245914  
 -0.0536814    0.0242642    0.0735677       0.00563232   0.120726  
 -0.00965531   0.067214     0.013369        0.0715948   -0.0987171 
  0.0491184   -0.0539577    0.00444167  …   0.0140791    0.0152978 
  0.00182314   0.0958121   -0.0597659      -0.0146108   -0.203456  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 21 28 32
INFO: iteration 1, average log likelihood -1.020279
WARNING: Variances had to be floored 7 21 26 28 32
INFO: iteration 2, average log likelihood -0.966712
WARNING: Variances had to be floored 2 6 11 14 18 20 21 22 24 28 30 32
INFO: iteration 3, average log likelihood -0.941917
WARNING: Variances had to be floored 7 21 23 26 28 32
INFO: iteration 4, average log likelihood -0.994631
WARNING: Variances had to be floored 2 14 21 28 32
INFO: iteration 5, average log likelihood -0.973587
WARNING: Variances had to be floored 6 7 11 18 20 21 22 24 26 28 30 32
INFO: iteration 6, average log likelihood -0.938146
WARNING: Variances had to be floored 2 14 21 23 28 32
INFO: iteration 7, average log likelihood -0.998520
WARNING: Variances had to be floored 7 21 26 28 32
INFO: iteration 8, average log likelihood -0.969324
WARNING: Variances had to be floored 2 6 11 18 20 21 22 24 28 30 32
INFO: iteration 9, average log likelihood -0.941213
WARNING: Variances had to be floored 7 14 21 23 26 28 32
INFO: iteration 10, average log likelihood -0.989548
INFO: EM with 100000 data points 10 iterations avll -0.989548
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.0575416    0.0185119   -0.0247581  …  -0.114488     0.0666972 
  0.0893543   -0.0649038   -0.0417742     -0.0424463    0.0586792 
 -0.0748869    0.0446104    0.0841444      0.076335    -0.142419  
  0.0909588    0.0526107    0.0319526      0.00428867   0.229392  
 -0.0797208    0.0297939   -0.104105      -0.0842643   -0.0151174 
  0.0927988   -0.0817328   -0.127726   …   0.110046     0.150543  
  0.0618815    0.0075947   -0.0677021      0.0693782    0.0576074 
 -0.0193195    0.0346325    0.0592563      0.080569     0.100649  
  0.0167445   -0.0407464    0.201235       0.0128567    0.122479  
 -0.0128932   -0.00766726   0.0547636      0.129173     0.0103026 
  ⋮                                    ⋱                ⋮         
 -0.0263432   -0.15916     -0.0490795     -0.0181594    0.0809627 
 -0.116618     0.0360532    0.0748621      0.0717177    0.060271  
 -0.00136238  -0.132084    -0.0205688  …   0.0845206   -0.0670842 
  0.11775      0.145715     0.111935      -0.0524319   -0.0887089 
 -0.00843593  -0.191939    -0.0637707      0.165563     0.00545536
  0.156358     0.0148196   -0.282858       0.0841499    0.105846  
  0.0476926   -0.0232473   -0.0784359      0.0523485    0.0651092 
 -0.029458     0.12926      0.0921305  …   0.0286459    0.166342  
  0.0127801    0.196099     0.11996       -0.00117895  -0.00531337kind full, method split
0: avll = -1.4156552308889292
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.415674
INFO: iteration 2, average log likelihood -1.415608
INFO: iteration 3, average log likelihood -1.415560
INFO: iteration 4, average log likelihood -1.415505
INFO: iteration 5, average log likelihood -1.415436
INFO: iteration 6, average log likelihood -1.415337
INFO: iteration 7, average log likelihood -1.415162
INFO: iteration 8, average log likelihood -1.414809
INFO: iteration 9, average log likelihood -1.414106
INFO: iteration 10, average log likelihood -1.412983
INFO: iteration 11, average log likelihood -1.411750
INFO: iteration 12, average log likelihood -1.410888
INFO: iteration 13, average log likelihood -1.410475
INFO: iteration 14, average log likelihood -1.410313
INFO: iteration 15, average log likelihood -1.410253
INFO: iteration 16, average log likelihood -1.410230
INFO: iteration 17, average log likelihood -1.410221
INFO: iteration 18, average log likelihood -1.410218
INFO: iteration 19, average log likelihood -1.410216
INFO: iteration 20, average log likelihood -1.410215
INFO: iteration 21, average log likelihood -1.410215
INFO: iteration 22, average log likelihood -1.410215
INFO: iteration 23, average log likelihood -1.410214
INFO: iteration 24, average log likelihood -1.410214
INFO: iteration 25, average log likelihood -1.410214
INFO: iteration 26, average log likelihood -1.410214
INFO: iteration 27, average log likelihood -1.410214
INFO: iteration 28, average log likelihood -1.410214
INFO: iteration 29, average log likelihood -1.410213
INFO: iteration 30, average log likelihood -1.410213
INFO: iteration 31, average log likelihood -1.410213
INFO: iteration 32, average log likelihood -1.410213
INFO: iteration 33, average log likelihood -1.410213
INFO: iteration 34, average log likelihood -1.410213
INFO: iteration 35, average log likelihood -1.410213
INFO: iteration 36, average log likelihood -1.410213
INFO: iteration 37, average log likelihood -1.410213
INFO: iteration 38, average log likelihood -1.410213
INFO: iteration 39, average log likelihood -1.410213
INFO: iteration 40, average log likelihood -1.410213
INFO: iteration 41, average log likelihood -1.410213
INFO: iteration 42, average log likelihood -1.410213
INFO: iteration 43, average log likelihood -1.410213
INFO: iteration 44, average log likelihood -1.410213
INFO: iteration 45, average log likelihood -1.410213
INFO: iteration 46, average log likelihood -1.410213
INFO: iteration 47, average log likelihood -1.410213
INFO: iteration 48, average log likelihood -1.410213
INFO: iteration 49, average log likelihood -1.410213
INFO: iteration 50, average log likelihood -1.410213
INFO: EM with 100000 data points 50 iterations avll -1.410213
952.4 data points per parameter
1: avll = [-1.4156735581852513,-1.4156078522988125,-1.4155599622942616,-1.4155053799223525,-1.41543645716769,-1.4153368173065326,-1.4151624440041133,-1.4148088216612833,-1.414106304081228,-1.412982839038115,-1.4117500574429511,-1.4108880469384983,-1.410474941316418,-1.4103129101576712,-1.4102526303804617,-1.4102299694458431,-1.4102212027080157,-1.410217659099436,-1.4102161149786356,-1.4102153530835992,-1.4102149083819076,-1.4102146011732175,-1.4102143608432314,-1.4102141587682033,-1.4102139826256355,-1.410213826511961,-1.4102136871217714,-1.410213562260093,-1.4102134502558326,-1.4102133497247866,-1.4102132594690737,-1.4102131784304093,-1.4102131056650875,-1.4102130403281183,-1.4102129816615483,-1.4102129289849779,-1.410212881687431,-1.410212839220205,-1.4102128010905035,-1.4102127668557405,-1.4102127361184285,-1.4102127085215916,-1.4102126837446418,-1.410212661499679,-1.41021264152816,-1.4102126235979136,-1.4102126075004524,-1.4102125930485614,-1.4102125800741303,-1.4102125684262077]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.410228
INFO: iteration 2, average log likelihood -1.410161
INFO: iteration 3, average log likelihood -1.410108
INFO: iteration 4, average log likelihood -1.410049
INFO: iteration 5, average log likelihood -1.409980
INFO: iteration 6, average log likelihood -1.409903
INFO: iteration 7, average log likelihood -1.409820
INFO: iteration 8, average log likelihood -1.409737
INFO: iteration 9, average log likelihood -1.409660
INFO: iteration 10, average log likelihood -1.409593
INFO: iteration 11, average log likelihood -1.409538
INFO: iteration 12, average log likelihood -1.409496
INFO: iteration 13, average log likelihood -1.409465
INFO: iteration 14, average log likelihood -1.409444
INFO: iteration 15, average log likelihood -1.409430
INFO: iteration 16, average log likelihood -1.409420
INFO: iteration 17, average log likelihood -1.409414
INFO: iteration 18, average log likelihood -1.409409
INFO: iteration 19, average log likelihood -1.409406
INFO: iteration 20, average log likelihood -1.409403
INFO: iteration 21, average log likelihood -1.409400
INFO: iteration 22, average log likelihood -1.409398
INFO: iteration 23, average log likelihood -1.409396
INFO: iteration 24, average log likelihood -1.409394
INFO: iteration 25, average log likelihood -1.409392
INFO: iteration 26, average log likelihood -1.409390
INFO: iteration 27, average log likelihood -1.409387
INFO: iteration 28, average log likelihood -1.409385
INFO: iteration 29, average log likelihood -1.409382
INFO: iteration 30, average log likelihood -1.409380
INFO: iteration 31, average log likelihood -1.409377
INFO: iteration 32, average log likelihood -1.409374
INFO: iteration 33, average log likelihood -1.409371
INFO: iteration 34, average log likelihood -1.409368
INFO: iteration 35, average log likelihood -1.409364
INFO: iteration 36, average log likelihood -1.409361
INFO: iteration 37, average log likelihood -1.409357
INFO: iteration 38, average log likelihood -1.409353
INFO: iteration 39, average log likelihood -1.409348
INFO: iteration 40, average log likelihood -1.409344
INFO: iteration 41, average log likelihood -1.409339
INFO: iteration 42, average log likelihood -1.409334
INFO: iteration 43, average log likelihood -1.409329
INFO: iteration 44, average log likelihood -1.409323
INFO: iteration 45, average log likelihood -1.409317
INFO: iteration 46, average log likelihood -1.409311
INFO: iteration 47, average log likelihood -1.409305
INFO: iteration 48, average log likelihood -1.409298
INFO: iteration 49, average log likelihood -1.409291
INFO: iteration 50, average log likelihood -1.409284
INFO: EM with 100000 data points 50 iterations avll -1.409284
473.9 data points per parameter
2: avll = [-1.4102275701939089,-1.4101612968669897,-1.4101080193017583,-1.410048703612659,-1.4099802030343596,-1.4099028697663578,-1.4098201355861089,-1.4097373657937833,-1.4096601410010787,-1.409592817025267,-1.4095378339625264,-1.4094956421957228,-1.4094650457927218,-1.4094438494365868,-1.409429586811807,-1.409420061745317,-1.4094135893917235,-1.4094090020902406,-1.4094055437307922,-1.409402744688235,-1.4094003191150923,-1.4093980933135186,-1.4093959600922792,-1.4093938511569877,-1.4093917208800473,-1.4093895368844744,-1.4093872745961156,-1.4093849140811956,-1.409382438201449,-1.4093798315378199,-1.4093770797723675,-1.4093741693521378,-1.4093710873336103,-1.4093678213478693,-1.4093643596493937,-1.4093606912234455,-1.4093568059330879,-1.409352694689505,-1.409348349630306,-1.4093437642909337,-1.409338933755157,-1.4093338547724878,-1.4093285258337276,-1.409322947200909,-1.4093171208944906,-1.4093110506482565,-1.409304741850058,-1.4092982014930024,-1.4092914381654795,-1.4092844621080045]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409287
INFO: iteration 2, average log likelihood -1.409232
INFO: iteration 3, average log likelihood -1.409183
INFO: iteration 4, average log likelihood -1.409124
INFO: iteration 5, average log likelihood -1.409052
INFO: iteration 6, average log likelihood -1.408964
INFO: iteration 7, average log likelihood -1.408862
INFO: iteration 8, average log likelihood -1.408753
INFO: iteration 9, average log likelihood -1.408645
INFO: iteration 10, average log likelihood -1.408547
INFO: iteration 11, average log likelihood -1.408462
INFO: iteration 12, average log likelihood -1.408388
INFO: iteration 13, average log likelihood -1.408324
INFO: iteration 14, average log likelihood -1.408267
INFO: iteration 15, average log likelihood -1.408217
INFO: iteration 16, average log likelihood -1.408172
INFO: iteration 17, average log likelihood -1.408132
INFO: iteration 18, average log likelihood -1.408096
INFO: iteration 19, average log likelihood -1.408064
INFO: iteration 20, average log likelihood -1.408037
INFO: iteration 21, average log likelihood -1.408012
INFO: iteration 22, average log likelihood -1.407991
INFO: iteration 23, average log likelihood -1.407973
INFO: iteration 24, average log likelihood -1.407956
INFO: iteration 25, average log likelihood -1.407942
INFO: iteration 26, average log likelihood -1.407929
INFO: iteration 27, average log likelihood -1.407918
INFO: iteration 28, average log likelihood -1.407908
INFO: iteration 29, average log likelihood -1.407899
INFO: iteration 30, average log likelihood -1.407890
INFO: iteration 31, average log likelihood -1.407883
INFO: iteration 32, average log likelihood -1.407876
INFO: iteration 33, average log likelihood -1.407870
INFO: iteration 34, average log likelihood -1.407864
INFO: iteration 35, average log likelihood -1.407858
INFO: iteration 36, average log likelihood -1.407853
INFO: iteration 37, average log likelihood -1.407848
INFO: iteration 38, average log likelihood -1.407843
INFO: iteration 39, average log likelihood -1.407839
INFO: iteration 40, average log likelihood -1.407834
INFO: iteration 41, average log likelihood -1.407830
INFO: iteration 42, average log likelihood -1.407826
INFO: iteration 43, average log likelihood -1.407822
INFO: iteration 44, average log likelihood -1.407818
INFO: iteration 45, average log likelihood -1.407814
INFO: iteration 46, average log likelihood -1.407810
INFO: iteration 47, average log likelihood -1.407806
INFO: iteration 48, average log likelihood -1.407803
INFO: iteration 49, average log likelihood -1.407799
INFO: iteration 50, average log likelihood -1.407795
INFO: EM with 100000 data points 50 iterations avll -1.407795
236.4 data points per parameter
3: avll = [-1.4092870574840162,-1.4092323702712384,-1.4091825436406382,-1.4091241887764845,-1.4090521285704245,-1.40896404229823,-1.4088619489976564,-1.4087526347355486,-1.4086452829410487,-1.4085473284274228,-1.4084618565691156,-1.4083881898349364,-1.4083240933725418,-1.4082674791913303,-1.4082169812895415,-1.4081718373655219,-1.4081315977484752,-1.408095909426855,-1.408064415329095,-1.408036730952072,-1.4080124553205833,-1.4079911899542548,-1.4079725547036444,-1.4079561977889608,-1.4079418007735487,-1.407929080019734,-1.4079177859966834,-1.4079077013904024,-1.4078986385943455,-1.4078904369109946,-1.407882959656631,-1.4078760912932369,-1.4078697346769087,-1.4078638084892707,-1.4078582448977714,-1.4078529874707597,-1.407847989355081,-1.4078432117092095,-1.407838622374329,-1.4078341947592758,-1.407829906912188,-1.407825740751243,-1.4078216814281974,-1.4078177168008061,-1.4078138369931734,-1.4078100340261974,-1.407806301503376,-1.4078026343401313,-1.4077990285274533,-1.4077954809229711]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407802
INFO: iteration 2, average log likelihood -1.407750
INFO: iteration 3, average log likelihood -1.407704
INFO: iteration 4, average log likelihood -1.407652
INFO: iteration 5, average log likelihood -1.407589
INFO: iteration 6, average log likelihood -1.407513
INFO: iteration 7, average log likelihood -1.407424
INFO: iteration 8, average log likelihood -1.407325
INFO: iteration 9, average log likelihood -1.407220
INFO: iteration 10, average log likelihood -1.407113
INFO: iteration 11, average log likelihood -1.407009
INFO: iteration 12, average log likelihood -1.406910
INFO: iteration 13, average log likelihood -1.406818
INFO: iteration 14, average log likelihood -1.406735
INFO: iteration 15, average log likelihood -1.406659
INFO: iteration 16, average log likelihood -1.406591
INFO: iteration 17, average log likelihood -1.406531
INFO: iteration 18, average log likelihood -1.406477
INFO: iteration 19, average log likelihood -1.406430
INFO: iteration 20, average log likelihood -1.406388
INFO: iteration 21, average log likelihood -1.406351
INFO: iteration 22, average log likelihood -1.406317
INFO: iteration 23, average log likelihood -1.406287
INFO: iteration 24, average log likelihood -1.406260
INFO: iteration 25, average log likelihood -1.406234
INFO: iteration 26, average log likelihood -1.406211
INFO: iteration 27, average log likelihood -1.406190
INFO: iteration 28, average log likelihood -1.406170
INFO: iteration 29, average log likelihood -1.406152
INFO: iteration 30, average log likelihood -1.406135
INFO: iteration 31, average log likelihood -1.406118
INFO: iteration 32, average log likelihood -1.406103
INFO: iteration 33, average log likelihood -1.406088
INFO: iteration 34, average log likelihood -1.406074
INFO: iteration 35, average log likelihood -1.406060
INFO: iteration 36, average log likelihood -1.406047
INFO: iteration 37, average log likelihood -1.406034
INFO: iteration 38, average log likelihood -1.406022
INFO: iteration 39, average log likelihood -1.406010
INFO: iteration 40, average log likelihood -1.405999
INFO: iteration 41, average log likelihood -1.405987
INFO: iteration 42, average log likelihood -1.405976
INFO: iteration 43, average log likelihood -1.405965
INFO: iteration 44, average log likelihood -1.405954
INFO: iteration 45, average log likelihood -1.405943
INFO: iteration 46, average log likelihood -1.405932
INFO: iteration 47, average log likelihood -1.405922
INFO: iteration 48, average log likelihood -1.405911
INFO: iteration 49, average log likelihood -1.405901
INFO: iteration 50, average log likelihood -1.405890
INFO: EM with 100000 data points 50 iterations avll -1.405890
118.1 data points per parameter
4: avll = [-1.4078017259998017,-1.4077495684682062,-1.4077036817530761,-1.4076516063041031,-1.4075888955407914,-1.4075131606887794,-1.407424390985389,-1.4073250867765097,-1.4072195887238392,-1.4071127351214623,-1.4070086029831534,-1.4069099521859147,-1.4068183485872392,-1.406734548256892,-1.4066588038699634,-1.4065910087815965,-1.4065307560068092,-1.4064774026704632,-1.4064301671381962,-1.4063882338920723,-1.4063508340077564,-1.4063172883355033,-1.406287019000616,-1.4062595420740858,-1.4062344528985384,-1.4062114111091708,-1.4061901283280729,-1.4061703589814476,-1.4061518935768085,-1.4061345535596474,-1.4061181870582307,-1.4061026651085642,-1.4060878781836748,-1.4060737329936748,-1.406060149587672,-1.406047058801962,-1.4060344000853167,-1.4060221197086857,-1.4060101693433136,-1.4059985049732593,-1.4059870860973238,-1.4059758751711313,-1.4059648372413187,-1.405953939728659,-1.4059431523237875,-1.4059324469664944,-1.4059217978862708,-1.4059111816872598,-1.405900577464641,-1.4058899669417682]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.405887
INFO: iteration 2, average log likelihood -1.405824
INFO: iteration 3, average log likelihood -1.405764
INFO: iteration 4, average log likelihood -1.405693
INFO: iteration 5, average log likelihood -1.405606
INFO: iteration 6, average log likelihood -1.405498
INFO: iteration 7, average log likelihood -1.405369
INFO: iteration 8, average log likelihood -1.405220
INFO: iteration 9, average log likelihood -1.405060
INFO: iteration 10, average log likelihood -1.404895
INFO: iteration 11, average log likelihood -1.404732
INFO: iteration 12, average log likelihood -1.404577
INFO: iteration 13, average log likelihood -1.404433
INFO: iteration 14, average log likelihood -1.404302
INFO: iteration 15, average log likelihood -1.404185
INFO: iteration 16, average log likelihood -1.404081
INFO: iteration 17, average log likelihood -1.403990
INFO: iteration 18, average log likelihood -1.403909
INFO: iteration 19, average log likelihood -1.403838
INFO: iteration 20, average log likelihood -1.403774
INFO: iteration 21, average log likelihood -1.403717
INFO: iteration 22, average log likelihood -1.403664
INFO: iteration 23, average log likelihood -1.403616
INFO: iteration 24, average log likelihood -1.403570
INFO: iteration 25, average log likelihood -1.403528
INFO: iteration 26, average log likelihood -1.403488
INFO: iteration 27, average log likelihood -1.403450
INFO: iteration 28, average log likelihood -1.403414
INFO: iteration 29, average log likelihood -1.403379
INFO: iteration 30, average log likelihood -1.403346
INFO: iteration 31, average log likelihood -1.403314
INFO: iteration 32, average log likelihood -1.403283
INFO: iteration 33, average log likelihood -1.403254
INFO: iteration 34, average log likelihood -1.403226
INFO: iteration 35, average log likelihood -1.403200
INFO: iteration 36, average log likelihood -1.403175
INFO: iteration 37, average log likelihood -1.403150
INFO: iteration 38, average log likelihood -1.403128
INFO: iteration 39, average log likelihood -1.403106
INFO: iteration 40, average log likelihood -1.403085
INFO: iteration 41, average log likelihood -1.403065
INFO: iteration 42, average log likelihood -1.403046
INFO: iteration 43, average log likelihood -1.403027
INFO: iteration 44, average log likelihood -1.403009
INFO: iteration 45, average log likelihood -1.402992
INFO: iteration 46, average log likelihood -1.402976
INFO: iteration 47, average log likelihood -1.402960
INFO: iteration 48, average log likelihood -1.402944
INFO: iteration 49, average log likelihood -1.402929
INFO: iteration 50, average log likelihood -1.402914
INFO: EM with 100000 data points 50 iterations avll -1.402914
59.0 data points per parameter
5: avll = [-1.4058869911076561,-1.405824332328549,-1.4057637822366364,-1.4056930987231875,-1.405605937675939,-1.4054981367295816,-1.405368652478013,-1.4052204089956766,-1.4050597852900097,-1.4048945665685286,-1.4047317718715184,-1.4045766787718676,-1.4044327704073845,-1.4043019497419955,-1.404184873556993,-1.404081222007885,-1.403989933808269,-1.403909487292223,-1.403838198111307,-1.4037744550316325,-1.403716852136452,-1.4036642305654792,-1.4036156672859186,-1.4035704431057436,-1.403528006191033,-1.4034879357440102,-1.4034499084301333,-1.4034136719165944,-1.4033790288389274,-1.4033458316679879,-1.403313985501944,-1.4032834498253368,-1.403254226991896,-1.4032263341503655,-1.4031997715334825,-1.4031745047538489,-1.4031504665520633,-1.4031275699982868,-1.4031057225722432,-1.4030848354753407,-1.4030648275863011,-1.4030456258734447,-1.4030271643658567,-1.4030093830835322,-1.40299222746266,-1.4029756482299027,-1.402959601462196,-1.4029440485911642,-1.4029289562257505,-1.4029142957817522]
[-1.4156552308889292,-1.4156735581852513,-1.4156078522988125,-1.4155599622942616,-1.4155053799223525,-1.41543645716769,-1.4153368173065326,-1.4151624440041133,-1.4148088216612833,-1.414106304081228,-1.412982839038115,-1.4117500574429511,-1.4108880469384983,-1.410474941316418,-1.4103129101576712,-1.4102526303804617,-1.4102299694458431,-1.4102212027080157,-1.410217659099436,-1.4102161149786356,-1.4102153530835992,-1.4102149083819076,-1.4102146011732175,-1.4102143608432314,-1.4102141587682033,-1.4102139826256355,-1.410213826511961,-1.4102136871217714,-1.410213562260093,-1.4102134502558326,-1.4102133497247866,-1.4102132594690737,-1.4102131784304093,-1.4102131056650875,-1.4102130403281183,-1.4102129816615483,-1.4102129289849779,-1.410212881687431,-1.410212839220205,-1.4102128010905035,-1.4102127668557405,-1.4102127361184285,-1.4102127085215916,-1.4102126837446418,-1.410212661499679,-1.41021264152816,-1.4102126235979136,-1.4102126075004524,-1.4102125930485614,-1.4102125800741303,-1.4102125684262077,-1.4102275701939089,-1.4101612968669897,-1.4101080193017583,-1.410048703612659,-1.4099802030343596,-1.4099028697663578,-1.4098201355861089,-1.4097373657937833,-1.4096601410010787,-1.409592817025267,-1.4095378339625264,-1.4094956421957228,-1.4094650457927218,-1.4094438494365868,-1.409429586811807,-1.409420061745317,-1.4094135893917235,-1.4094090020902406,-1.4094055437307922,-1.409402744688235,-1.4094003191150923,-1.4093980933135186,-1.4093959600922792,-1.4093938511569877,-1.4093917208800473,-1.4093895368844744,-1.4093872745961156,-1.4093849140811956,-1.409382438201449,-1.4093798315378199,-1.4093770797723675,-1.4093741693521378,-1.4093710873336103,-1.4093678213478693,-1.4093643596493937,-1.4093606912234455,-1.4093568059330879,-1.409352694689505,-1.409348349630306,-1.4093437642909337,-1.409338933755157,-1.4093338547724878,-1.4093285258337276,-1.409322947200909,-1.4093171208944906,-1.4093110506482565,-1.409304741850058,-1.4092982014930024,-1.4092914381654795,-1.4092844621080045,-1.4092870574840162,-1.4092323702712384,-1.4091825436406382,-1.4091241887764845,-1.4090521285704245,-1.40896404229823,-1.4088619489976564,-1.4087526347355486,-1.4086452829410487,-1.4085473284274228,-1.4084618565691156,-1.4083881898349364,-1.4083240933725418,-1.4082674791913303,-1.4082169812895415,-1.4081718373655219,-1.4081315977484752,-1.408095909426855,-1.408064415329095,-1.408036730952072,-1.4080124553205833,-1.4079911899542548,-1.4079725547036444,-1.4079561977889608,-1.4079418007735487,-1.407929080019734,-1.4079177859966834,-1.4079077013904024,-1.4078986385943455,-1.4078904369109946,-1.407882959656631,-1.4078760912932369,-1.4078697346769087,-1.4078638084892707,-1.4078582448977714,-1.4078529874707597,-1.407847989355081,-1.4078432117092095,-1.407838622374329,-1.4078341947592758,-1.407829906912188,-1.407825740751243,-1.4078216814281974,-1.4078177168008061,-1.4078138369931734,-1.4078100340261974,-1.407806301503376,-1.4078026343401313,-1.4077990285274533,-1.4077954809229711,-1.4078017259998017,-1.4077495684682062,-1.4077036817530761,-1.4076516063041031,-1.4075888955407914,-1.4075131606887794,-1.407424390985389,-1.4073250867765097,-1.4072195887238392,-1.4071127351214623,-1.4070086029831534,-1.4069099521859147,-1.4068183485872392,-1.406734548256892,-1.4066588038699634,-1.4065910087815965,-1.4065307560068092,-1.4064774026704632,-1.4064301671381962,-1.4063882338920723,-1.4063508340077564,-1.4063172883355033,-1.406287019000616,-1.4062595420740858,-1.4062344528985384,-1.4062114111091708,-1.4061901283280729,-1.4061703589814476,-1.4061518935768085,-1.4061345535596474,-1.4061181870582307,-1.4061026651085642,-1.4060878781836748,-1.4060737329936748,-1.406060149587672,-1.406047058801962,-1.4060344000853167,-1.4060221197086857,-1.4060101693433136,-1.4059985049732593,-1.4059870860973238,-1.4059758751711313,-1.4059648372413187,-1.405953939728659,-1.4059431523237875,-1.4059324469664944,-1.4059217978862708,-1.4059111816872598,-1.405900577464641,-1.4058899669417682,-1.4058869911076561,-1.405824332328549,-1.4057637822366364,-1.4056930987231875,-1.405605937675939,-1.4054981367295816,-1.405368652478013,-1.4052204089956766,-1.4050597852900097,-1.4048945665685286,-1.4047317718715184,-1.4045766787718676,-1.4044327704073845,-1.4043019497419955,-1.404184873556993,-1.404081222007885,-1.403989933808269,-1.403909487292223,-1.403838198111307,-1.4037744550316325,-1.403716852136452,-1.4036642305654792,-1.4036156672859186,-1.4035704431057436,-1.403528006191033,-1.4034879357440102,-1.4034499084301333,-1.4034136719165944,-1.4033790288389274,-1.4033458316679879,-1.403313985501944,-1.4032834498253368,-1.403254226991896,-1.4032263341503655,-1.4031997715334825,-1.4031745047538489,-1.4031504665520633,-1.4031275699982868,-1.4031057225722432,-1.4030848354753407,-1.4030648275863011,-1.4030456258734447,-1.4030271643658567,-1.4030093830835322,-1.40299222746266,-1.4029756482299027,-1.402959601462196,-1.4029440485911642,-1.4029289562257505,-1.4029142957817522]
32x26 Array{Float64,2}:
  0.934445     0.0379439  -0.265119   …  -0.373217    0.102085    0.644202 
  0.492645     0.0831506  -0.72915       -0.398102    0.0945674   0.135563 
  0.343117     0.0363583  -0.0878058     -0.164659    0.269931    0.123733 
 -0.0112839   -0.230419    0.535708      -0.604088    0.133362    0.738046 
 -0.344888     0.275504   -0.155225       0.121068    0.181736   -0.736088 
  0.356608     0.525821   -0.764341   …  -0.534445   -0.25566    -0.411808 
  0.27162     -0.0758815  -0.0496125      0.189573   -0.0980858   0.0273275
 -0.0202718   -0.360622    0.101745       0.170263   -0.131897    0.343054 
  0.00191209  -0.665229   -0.0817953      0.871835    0.238777    0.0146633
 -0.0860082   -0.477021    0.055824       0.560619    0.304563    0.0454169
  ⋮                                   ⋱                           ⋮        
  0.243371     0.198254   -0.238839       0.165783    0.293033   -0.428458 
 -0.164506    -0.155708   -0.140622      -0.469358    0.092771    0.235937 
 -0.0129723   -0.237075    0.491801   …  -0.316786   -0.085329    0.437035 
 -0.0822828   -0.111206    0.165927       0.447524   -0.200558    0.0583892
 -0.279914    -0.161226    0.0796188      0.0191312   0.243594    0.123508 
  0.30379     -0.288437   -0.215963      -0.247642    0.384504    0.0444774
  0.441295    -0.275802   -0.242979      -0.109259    0.633908    0.032906 
  0.0508093    0.127522   -0.18125    …   0.415126    0.0409895  -0.261829 
  0.527632    -0.743951   -0.682093       0.226562   -0.0314722   0.342913 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402900
INFO: iteration 2, average log likelihood -1.402886
INFO: iteration 3, average log likelihood -1.402873
INFO: iteration 4, average log likelihood -1.402860
INFO: iteration 5, average log likelihood -1.402847
INFO: iteration 6, average log likelihood -1.402834
INFO: iteration 7, average log likelihood -1.402822
INFO: iteration 8, average log likelihood -1.402810
INFO: iteration 9, average log likelihood -1.402799
INFO: iteration 10, average log likelihood -1.402787
INFO: EM with 100000 data points 10 iterations avll -1.402787
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.244865e+05
      1       6.947300e+05      -2.297566e+05 |       32
      2       6.813890e+05      -1.334097e+04 |       32
      3       6.759834e+05      -5.405589e+03 |       32
      4       6.731367e+05      -2.846671e+03 |       32
      5       6.713869e+05      -1.749854e+03 |       32
      6       6.701653e+05      -1.221599e+03 |       32
      7       6.692753e+05      -8.899705e+02 |       32
      8       6.685654e+05      -7.099302e+02 |       32
      9       6.679917e+05      -5.736496e+02 |       32
     10       6.675269e+05      -4.648284e+02 |       32
     11       6.671558e+05      -3.711324e+02 |       32
     12       6.668459e+05      -3.098971e+02 |       32
     13       6.665707e+05      -2.751873e+02 |       32
     14       6.663400e+05      -2.306299e+02 |       32
     15       6.661423e+05      -1.977467e+02 |       32
     16       6.659592e+05      -1.831466e+02 |       32
     17       6.657923e+05      -1.668069e+02 |       32
     18       6.656552e+05      -1.371893e+02 |       32
     19       6.655289e+05      -1.262827e+02 |       32
     20       6.654058e+05      -1.230735e+02 |       32
     21       6.652681e+05      -1.377159e+02 |       32
     22       6.651314e+05      -1.366830e+02 |       32
     23       6.650093e+05      -1.220878e+02 |       32
     24       6.648922e+05      -1.171362e+02 |       32
     25       6.647946e+05      -9.759103e+01 |       32
     26       6.647001e+05      -9.446915e+01 |       32
     27       6.646184e+05      -8.172981e+01 |       32
     28       6.645428e+05      -7.556270e+01 |       32
     29       6.644722e+05      -7.058236e+01 |       32
     30       6.644079e+05      -6.432758e+01 |       32
     31       6.643454e+05      -6.255817e+01 |       32
     32       6.642930e+05      -5.233985e+01 |       32
     33       6.642358e+05      -5.718457e+01 |       32
     34       6.641831e+05      -5.275903e+01 |       32
     35       6.641344e+05      -4.871577e+01 |       32
     36       6.640887e+05      -4.562729e+01 |       32
     37       6.640515e+05      -3.727190e+01 |       32
     38       6.640209e+05      -3.054993e+01 |       32
     39       6.639976e+05      -2.331976e+01 |       32
     40       6.639774e+05      -2.023991e+01 |       32
     41       6.639548e+05      -2.253194e+01 |       32
     42       6.639300e+05      -2.479248e+01 |       32
     43       6.639055e+05      -2.447814e+01 |       32
     44       6.638814e+05      -2.414157e+01 |       32
     45       6.638535e+05      -2.788182e+01 |       32
     46       6.638309e+05      -2.264968e+01 |       32
     47       6.638105e+05      -2.037906e+01 |       32
     48       6.637911e+05      -1.937545e+01 |       32
     49       6.637701e+05      -2.100097e+01 |       32
     50       6.637537e+05      -1.637780e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 663753.7429967292)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414862
INFO: iteration 2, average log likelihood -1.409731
INFO: iteration 3, average log likelihood -1.408274
INFO: iteration 4, average log likelihood -1.407120
INFO: iteration 5, average log likelihood -1.405943
INFO: iteration 6, average log likelihood -1.404969
INFO: iteration 7, average log likelihood -1.404368
INFO: iteration 8, average log likelihood -1.404043
INFO: iteration 9, average log likelihood -1.403855
INFO: iteration 10, average log likelihood -1.403727
INFO: iteration 11, average log likelihood -1.403630
INFO: iteration 12, average log likelihood -1.403551
INFO: iteration 13, average log likelihood -1.403484
INFO: iteration 14, average log likelihood -1.403427
INFO: iteration 15, average log likelihood -1.403376
INFO: iteration 16, average log likelihood -1.403332
INFO: iteration 17, average log likelihood -1.403292
INFO: iteration 18, average log likelihood -1.403255
INFO: iteration 19, average log likelihood -1.403222
INFO: iteration 20, average log likelihood -1.403192
INFO: iteration 21, average log likelihood -1.403164
INFO: iteration 22, average log likelihood -1.403138
INFO: iteration 23, average log likelihood -1.403114
INFO: iteration 24, average log likelihood -1.403091
INFO: iteration 25, average log likelihood -1.403069
INFO: iteration 26, average log likelihood -1.403048
INFO: iteration 27, average log likelihood -1.403028
INFO: iteration 28, average log likelihood -1.403009
INFO: iteration 29, average log likelihood -1.402990
INFO: iteration 30, average log likelihood -1.402972
INFO: iteration 31, average log likelihood -1.402953
INFO: iteration 32, average log likelihood -1.402936
INFO: iteration 33, average log likelihood -1.402918
INFO: iteration 34, average log likelihood -1.402900
INFO: iteration 35, average log likelihood -1.402882
INFO: iteration 36, average log likelihood -1.402865
INFO: iteration 37, average log likelihood -1.402847
INFO: iteration 38, average log likelihood -1.402830
INFO: iteration 39, average log likelihood -1.402812
INFO: iteration 40, average log likelihood -1.402794
INFO: iteration 41, average log likelihood -1.402777
INFO: iteration 42, average log likelihood -1.402759
INFO: iteration 43, average log likelihood -1.402742
INFO: iteration 44, average log likelihood -1.402724
INFO: iteration 45, average log likelihood -1.402707
INFO: iteration 46, average log likelihood -1.402690
INFO: iteration 47, average log likelihood -1.402673
INFO: iteration 48, average log likelihood -1.402657
INFO: iteration 49, average log likelihood -1.402642
INFO: iteration 50, average log likelihood -1.402627
INFO: EM with 100000 data points 50 iterations avll -1.402627
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.271713    -0.227945   -0.112969   …  -0.0836106   0.516651    0.208037  
 -0.0240443   -0.204263   -0.130826       0.147089    0.344138    0.123175  
  0.318216    -0.247743    0.133025       0.211751    0.616342   -0.357057  
 -0.217678     0.754212    0.587888      -0.0174938  -0.125825   -0.0613042 
 -0.335015     0.142121    0.862491       0.11559    -0.0635831  -0.316094  
 -0.59334     -0.0625444  -0.217252   …  -0.159297   -0.152037   -0.0557909 
 -0.107038     0.448021   -0.615199      -0.263403    0.12112    -0.205622  
 -0.281364     0.354825   -0.169397       0.215257    0.0267185  -0.573345  
 -0.297759    -0.373227    0.0361574     -0.219104   -0.634899    0.486113  
 -0.143313    -0.0571099  -0.345803       0.451191   -0.551019   -0.108592  
  ⋮                                   ⋱                           ⋮         
 -0.03798      0.120453   -0.0400172     -0.0559727  -0.164084    0.00939768
  0.307926     0.140003   -0.212557       0.346083    0.181906   -0.512161  
  0.0502884    0.187464    0.315261   …  -0.835645   -0.0542708   0.0391892 
  0.0867342   -0.127335    0.296764       0.0288565   0.251843   -0.295592  
  0.00769195  -0.021513    0.0487067      0.293977    0.0523365  -0.0617549 
  0.875373     0.0570045  -0.289673      -0.499314    0.139828    0.635263  
 -0.0626531   -0.221185    0.212049       0.56795    -0.0689826   0.0945542 
  0.587996    -0.751865   -0.693331   …   0.289749    0.0342599   0.411786  
  0.485448     0.0727325  -0.312771       0.42211     0.222498   -0.592678  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402612
INFO: iteration 2, average log likelihood -1.402599
INFO: iteration 3, average log likelihood -1.402585
INFO: iteration 4, average log likelihood -1.402573
INFO: iteration 5, average log likelihood -1.402561
INFO: iteration 6, average log likelihood -1.402549
INFO: iteration 7, average log likelihood -1.402538
INFO: iteration 8, average log likelihood -1.402527
INFO: iteration 9, average log likelihood -1.402516
INFO: iteration 10, average log likelihood -1.402505
INFO: EM with 100000 data points 10 iterations avll -1.402505
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
