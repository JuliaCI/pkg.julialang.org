>>> 'Pkg.add("ScikitLearn")' log
INFO: Cloning cache of ScikitLearn from https://github.com/cstjean/ScikitLearn.jl.git
INFO: Installing BinDeps v0.6.0
INFO: Installing Conda v0.7.0
INFO: Installing DataArrays v0.4.1
INFO: Installing DataFrames v0.9.1
INFO: Installing DataStructures v0.6.1
INFO: Installing FileIO v0.5.1
INFO: Installing GZip v0.3.0
INFO: Installing Iterators v0.3.1
INFO: Installing MacroTools v0.3.7
INFO: Installing Parameters v0.7.2
INFO: Installing PyCall v1.14.0
INFO: Installing Reexport v0.0.3
INFO: Installing SHA v0.3.3
INFO: Installing ScikitLearn v0.3.0
INFO: Installing ScikitLearnBase v0.3.0
INFO: Installing SortingAlgorithms v0.1.1
INFO: Installing SpecialFunctions v0.2.0
INFO: Installing StatsBase v0.17.0
INFO: Installing URIParser v0.2.0
INFO: Building Conda
INFO: Building PyCall
INFO: Using the Python distribution in the Conda package by default.
To use a different Python version, set ENV["PYTHON"]="pythoncommand" and re-run Pkg.build("PyCall").
Fetching package metadata ...........
Solving package specifications: .

# All requested packages already installed.
# packages in environment at /home/vagrant/.julia/v0.5/Conda/deps/usr:
#
numpy                     1.13.1          py27_blas_openblas_200  [blas_openblas]  conda-forge
INFO: PyCall is using /home/vagrant/.julia/v0.5/Conda/deps/usr/bin/python (Python 2.7.13) at /home/vagrant/.julia/v0.5/Conda/deps/usr/bin/python, libpython = /home/vagrant/.julia/v0.5/Conda/deps/usr/lib/libpython2.7
INFO: /home/vagrant/.julia/v0.5/PyCall/deps/deps.jl has not changed
INFO: /home/vagrant/.julia/v0.5/PyCall/deps/PYTHON has not changed
INFO: Package database updated
INFO: METADATA is out-of-date — you may not have the latest version of ScikitLearn
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("ScikitLearn")' log
Julia Version 0.5.2
Commit f4c6c9d (2017-05-06 16:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-128-generic #177-Ubuntu SMP Tue Aug 8 11:40:23 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (730.1640625 MB free)
Uptime: 38387.0 sec
Load Avg:  1.00927734375  1.0615234375  1.28857421875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    2411689 s       2930 s     220284 s     775006 s         60 s
#2  3499 MHz     904802 s       3265 s     100934 s    2735321 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.5
2 required packages:
 - JSON                          0.13.0
 - ScikitLearn                   0.3.0
19 additional packages:
 - BinDeps                       0.6.0
 - Compat                        0.30.0
 - Conda                         0.7.0
 - DataArrays                    0.4.1
 - DataFrames                    0.9.1
 - DataStructures                0.6.1
 - FileIO                        0.5.1
 - GZip                          0.3.0
 - Iterators                     0.3.1
 - MacroTools                    0.3.7
 - Parameters                    0.7.2
 - PyCall                        1.14.0
 - Reexport                      0.0.3
 - SHA                           0.3.3
 - ScikitLearnBase               0.3.0
 - SortingAlgorithms             0.1.1
 - SpecialFunctions              0.2.0
 - StatsBase                     0.17.0
 - URIParser                     0.2.0
INFO: Computing test dependencies for ScikitLearn...
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Cloning cache of GaussianProcesses from https://github.com/STOR-i/GaussianProcesses.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing Blosc v0.3.0
INFO: Installing Calculus v0.2.2
INFO: Installing Clustering v0.8.0
INFO: Installing ColorTypes v0.5.2
INFO: Installing Colors v0.7.4
INFO: Installing DecisionTree v0.6.2
INFO: Installing DiffBase v0.1.0
INFO: Installing Distances v0.4.1
INFO: Installing Distributions v0.13.0
INFO: Installing FixedPointNumbers v0.3.9
INFO: Installing ForwardDiff v0.4.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing GaussianProcesses v0.4.0
INFO: Installing HDF5 v0.8.4
INFO: Installing JLD v0.6.11
INFO: Installing LaTeXStrings v0.2.1
INFO: Installing LegacyStrings v0.2.2
INFO: Installing LineSearches v0.1.5
INFO: Installing LowRankModels v0.2.0
INFO: Installing NBInclude v1.2.0
INFO: Installing NMF v0.2.5
INFO: Installing NaNMath v0.2.6
INFO: Installing NearestNeighbors v0.2.0
INFO: Installing Optim v0.7.8
INFO: Installing PDMats v0.7.0
INFO: Installing PositiveFactorizations v0.0.4
INFO: Installing PyPlot v2.3.2
INFO: Installing QuadGK v0.1.3
INFO: Installing RData v0.1.0
INFO: Installing RDatasets v0.2.0
INFO: Installing Rmath v0.2.0
INFO: Installing Roots v0.4.0
INFO: Installing StaticArrays v0.3.1
INFO: Installing StatsFuns v0.5.0
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Building Conda
INFO: Building PyCall
INFO: Using the Python distribution in the Conda package by default.
To use a different Python version, set ENV["PYTHON"]="pythoncommand" and re-run Pkg.build("PyCall").
Fetching package metadata ...........
Solving package specifications: .

# All requested packages already installed.
# packages in environment at /home/vagrant/.julia/v0.5/Conda/deps/usr:
#
numpy                     1.13.1          py27_blas_openblas_200  [blas_openblas]  conda-forge
INFO: PyCall is using /home/vagrant/.julia/v0.5/Conda/deps/usr/bin/python (Python 2.7.13) at /home/vagrant/.julia/v0.5/Conda/deps/usr/bin/python, libpython = /home/vagrant/.julia/v0.5/Conda/deps/usr/lib/libpython2.7
INFO: /home/vagrant/.julia/v0.5/PyCall/deps/deps.jl has not changed
INFO: /home/vagrant/.julia/v0.5/PyCall/deps/PYTHON has not changed
INFO: Testing ScikitLearn
INFO: Installing sklearn via the Conda scikit-learn package...
Fetching package metadata ...........
Solving package specifications: .

Package plan for installation in environment /home/vagrant/.julia/v0.5/Conda/deps/usr:

The following NEW packages will be INSTALLED:

    scikit-learn: 0.19.0-py27_blas_openblas_201 conda-forge [blas_openblas]

scikit-learn-0   0% |                              | ETA:  --:--:--   0.00  B/sscikit-learn-0   1% |                               | ETA:  0:00:06   2.12 MB/sscikit-learn-0   2% |                               | ETA:  0:00:04   3.05 MB/sscikit-learn-0   3% |#                              | ETA:  0:00:03   3.60 MB/sscikit-learn-0   4% |#                              | ETA:  0:00:03   4.00 MB/sscikit-learn-0   5% |#                              | ETA:  0:00:02   4.55 MB/sscikit-learn-0   6% |##                             | ETA:  0:00:02   5.04 MB/sscikit-learn-0   7% |##                             | ETA:  0:00:02   5.48 MB/sscikit-learn-0   8% |##                             | ETA:  0:00:02   5.92 MB/sscikit-learn-0  10% |###                            | ETA:  0:00:01   6.51 MB/sscikit-learn-0  11% |###                            | ETA:  0:00:01   6.85 MB/sscikit-learn-0  12% |###                            | ETA:  0:00:01   7.12 MB/sscikit-learn-0  13% |####                           | ETA:  0:00:01   7.67 MB/sscikit-learn-0  14% |####                           | ETA:  0:00:01   7.94 MB/sscikit-learn-0  15% |####                           | ETA:  0:00:01   8.46 MB/sscikit-learn-0  16% |#####                          | ETA:  0:00:01   8.67 MB/sscikit-learn-0  17% |#####                          | ETA:  0:00:01   9.15 MB/sscikit-learn-0  19% |#####                          | ETA:  0:00:01   9.36 MB/sscikit-learn-0  20% |######                         | ETA:  0:00:01   9.79 MB/sscikit-learn-0  21% |######                         | ETA:  0:00:01  10.00 MB/sscikit-learn-0  22% |######                         | ETA:  0:00:00  10.41 MB/sscikit-learn-0  23% |#######                        | ETA:  0:00:00  10.82 MB/sscikit-learn-0  24% |#######                        | ETA:  0:00:00  10.99 MB/sscikit-learn-0  25% |########                       | ETA:  0:00:00  11.38 MB/sscikit-learn-0  26% |########                       | ETA:  0:00:00  11.55 MB/sscikit-learn-0  28% |########                       | ETA:  0:00:00  11.90 MB/sscikit-learn-0  29% |#########                      | ETA:  0:00:00  12.25 MB/sscikit-learn-0  30% |#########                      | ETA:  0:00:00  12.53 MB/sscikit-learn-0  31% |#########                      | ETA:  0:00:01   5.05 MB/sscikit-learn-0  32% |##########                     | ETA:  0:00:01   5.21 MB/sscikit-learn-0  33% |##########                     | ETA:  0:00:01   5.37 MB/sscikit-learn-0  34% |##########                     | ETA:  0:00:01   5.53 MB/sscikit-learn-0  35% |###########                    | ETA:  0:00:01   5.70 MB/sscikit-learn-0  37% |###########                    | ETA:  0:00:01   5.76 MB/sscikit-learn-0  38% |###########                    | ETA:  0:00:01   5.85 MB/sscikit-learn-0  39% |############                   | ETA:  0:00:01   6.00 MB/sscikit-learn-0  40% |############                   | ETA:  0:00:01   6.15 MB/sscikit-learn-0  41% |############                   | ETA:  0:00:01   6.30 MB/sscikit-learn-0  42% |#############                  | ETA:  0:00:01   6.44 MB/sscikit-learn-0  43% |#############                  | ETA:  0:00:01   6.59 MB/sscikit-learn-0  44% |#############                  | ETA:  0:00:01   6.73 MB/sscikit-learn-0  46% |##############                 | ETA:  0:00:01   6.88 MB/sscikit-learn-0  47% |##############                 | ETA:  0:00:00   7.02 MB/sscikit-learn-0  48% |##############                 | ETA:  0:00:00   7.16 MB/sscikit-learn-0  49% |###############                | ETA:  0:00:00   7.31 MB/sscikit-learn-0  50% |###############                | ETA:  0:00:00   7.45 MB/sscikit-learn-0  51% |################               | ETA:  0:00:00   7.60 MB/sscikit-learn-0  52% |################               | ETA:  0:00:00   7.74 MB/sscikit-learn-0  53% |################               | ETA:  0:00:00   7.88 MB/sscikit-learn-0  55% |#################              | ETA:  0:00:00   8.02 MB/sscikit-learn-0  56% |#################              | ETA:  0:00:00   8.16 MB/sscikit-learn-0  57% |#################              | ETA:  0:00:00   8.29 MB/sscikit-learn-0  58% |##################             | ETA:  0:00:00   8.42 MB/sscikit-learn-0  59% |##################             | ETA:  0:00:00   8.56 MB/sscikit-learn-0  60% |##################             | ETA:  0:00:00   8.64 MB/sscikit-learn-0  61% |###################            | ETA:  0:00:00   8.44 MB/sscikit-learn-0  62% |###################            | ETA:  0:00:00   8.46 MB/sscikit-learn-0  64% |###################            | ETA:  0:00:00   8.40 MB/sscikit-learn-0  65% |####################           | ETA:  0:00:00   8.42 MB/sscikit-learn-0  66% |####################           | ETA:  0:00:00   8.46 MB/sscikit-learn-0  67% |####################           | ETA:  0:00:00   8.50 MB/sscikit-learn-0  68% |#####################          | ETA:  0:00:00   8.61 MB/sscikit-learn-0  69% |#####################          | ETA:  0:00:00   8.65 MB/sscikit-learn-0  70% |#####################          | ETA:  0:00:00   8.69 MB/sscikit-learn-0  71% |######################         | ETA:  0:00:00   8.80 MB/sscikit-learn-0  73% |######################         | ETA:  0:00:00   8.85 MB/sscikit-learn-0  74% |#######################        | ETA:  0:00:00   8.90 MB/sscikit-learn-0  75% |#######################        | ETA:  0:00:00   9.00 MB/sscikit-learn-0  76% |#######################        | ETA:  0:00:00   9.07 MB/sscikit-learn-0  77% |########################       | ETA:  0:00:00   9.16 MB/sscikit-learn-0  78% |########################       | ETA:  0:00:00   9.27 MB/sscikit-learn-0  79% |########################       | ETA:  0:00:00   9.32 MB/sscikit-learn-0  80% |#########################      | ETA:  0:00:00   9.43 MB/sscikit-learn-0  82% |#########################      | ETA:  0:00:00   9.49 MB/sscikit-learn-0  83% |#########################      | ETA:  0:00:00   9.59 MB/sscikit-learn-0  84% |##########################     | ETA:  0:00:00   9.69 MB/sscikit-learn-0  85% |##########################     | ETA:  0:00:00   9.75 MB/sscikit-learn-0  86% |##########################     | ETA:  0:00:00   9.85 MB/sscikit-learn-0  87% |###########################    | ETA:  0:00:00   9.94 MB/sscikit-learn-0  88% |###########################    | ETA:  0:00:00  10.01 MB/sscikit-learn-0  89% |###########################    | ETA:  0:00:00  10.12 MB/sscikit-learn-0  91% |############################   | ETA:  0:00:00  10.19 MB/sscikit-learn-0  92% |############################   | ETA:  0:00:00  10.19 MB/sscikit-learn-0  93% |############################   | ETA:  0:00:00  10.26 MB/sscikit-learn-0  94% |#############################  | ETA:  0:00:00  10.37 MB/sscikit-learn-0  95% |#############################  | ETA:  0:00:00  10.45 MB/sscikit-learn-0  96% |#############################  | ETA:  0:00:00  10.56 MB/sscikit-learn-0  97% |############################## | ETA:  0:00:00  10.66 MB/sscikit-learn-0  98% |############################## | ETA:  0:00:00  10.70 MB/sscikit-learn-0 100% |###############################| ETA:  0:00:00  10.68 MB/sscikit-learn-0 100% |###############################| Time: 0:00:01  10.66 MB/s
WARNING: Method definition describe(AbstractArray) in module StatsBase at /home/vagrant/.julia/v0.5/StatsBase/src/scalarstats.jl:560 overwritten in module DataFrames at /home/vagrant/.julia/v0.5/DataFrames/src/abstractdataframe/abstractdataframe.jl:407.
WARNING: Method definition describe(AbstractArray) in module StatsBase at /home/vagrant/.julia/v0.5/StatsBase/src/scalarstats.jl:560 overwritten in module DataFrames at /home/vagrant/.julia/v0.5/DataFrames/src/abstractdataframe/abstractdataframe.jl:407.
WARNING: redefining constant SVC
WARNING: redefining constant f_classif
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.
WARNING: redefining constant LogisticRegression
WARNING: redefining constant StandardScaler
Testing ../examples/Classifier_Comparison.ipynb
WARNING: No working GUI backend found for matplotlib
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
Testing ../examples/Classifier_Comparison_Julia.ipynb
WARNING: replacing module Testing
Testing ../examples/Clustering_Comparison.ipynb
WARNING: replacing module Testing
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.
  warnings.warn("Graph is not fully connected, spectral embedding"
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:193: UserWarning: the number of connected components of the connectivity matrix is 2 > 1. Completing it to avoid stopping the tree early.
  affinity='euclidean')
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:426: UserWarning: the number of connected components of the connectivity matrix is 2 > 1. Completing it to avoid stopping the tree early.
  affinity=affinity)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:193: UserWarning: the number of connected components of the connectivity matrix is 3 > 1. Completing it to avoid stopping the tree early.
  affinity='euclidean')
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:426: UserWarning: the number of connected components of the connectivity matrix is 3 > 1. Completing it to avoid stopping the tree early.
  affinity=affinity)
Testing ../examples/Cross_Validated_Predictions.ipynb
WARNING: replacing module Testing
Testing ../examples/Decision_Tree_Regression.ipynb
WARNING: replacing module Testing
Testing ../examples/Decision_Tree_Regression_Julia.ipynb
WARNING: replacing module Testing
Testing ../examples/Density_Estimation.ipynb
WARNING: replacing module Testing
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.
  warnings.warn(msg, category=DeprecationWarning)
Testing ../examples/Feature_Stacker.ipynb
WARNING: replacing module Testing
Fitting 3 folds for each of 18 candidates, totalling 54 fits
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1, score=0.96078  -  0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1, score=0.90196  -  0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=1, score=0.94118  -  0.0s
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=1, score=0.92157  -  0.0s
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=1, score=0.96078  -  0.0s
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=1, score=0.92157  -  0.0s
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2, score=0.96078  -  0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2, score=0.92157  -  0.0s
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=0.1, features__univ_select__k=2, score=0.97917  -  0.0s
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=2, score=0.96078  -  0.0s
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=2, score=0.92157  -  0.0s
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=1.0, features__univ_select__k=2, score=1.00000  -  0.0s
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=2, score=0.98039  -  0.0s
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=2, score=0.90196  -  0.0s
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=1, svm__C=10.0, features__univ_select__k=2, score=1.00000  -  0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1, score=0.96078  -  0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1, score=0.90196  -  0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=1, score=0.98039  -  0.0s
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=1, score=0.94118  -  0.0s
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=1, score=0.98039  -  0.0s
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=1, score=0.94118  -  0.0s
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2, score=0.98039  -  0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2, score=0.94118  -  0.0s
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=0.1, features__univ_select__k=2, score=0.97917  -  0.0s
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=2, score=1.00000  -  0.0s
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=2, score=0.96078  -  0.0s
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=1.0, features__univ_select__k=2, score=0.97917  -  0.0s
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=2, score=0.98039  -  0.0s
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=2, score=0.92157  -  0.0s
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=2, svm__C=10.0, features__univ_select__k=2, score=1.00000  -  0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1, score=0.98039  -  0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1, score=0.94118  -  0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=1, score=1.00000  -  0.0s
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=1, score=0.94118  -  0.0s
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=1, score=0.97917  -  0.0s
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=1, score=1.00000  -  0.0s
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=1, score=0.92157  -  0.0s
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=1
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=1, score=1.00000  -  0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2, score=0.98039  -  0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2, score=0.94118  -  0.0s
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=0.1, features__univ_select__k=2, score=0.97917  -  0.0s
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=2, score=1.00000  -  0.0s
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=2, score=0.96078  -  0.0s
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=1.0, features__univ_select__k=2, score=0.97917  -  0.0s
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=2, score=1.00000  -  0.0s
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=2, score=0.92157  -  0.0s
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=2
[CV] features__pca__n_components=3, svm__C=10.0, features__univ_select__k=2, score=1.00000  -  0.0s
ScikitLearn.Skcore.Pipeline(Tuple{Any,Any}[("features",ScikitLearn.Skcore.FeatureUnion(Tuple{Any,Any}[("pca",PyObject PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)),("univ_select",PyObject SelectKBest(k=2, score_func=<function f_classif at 0x7f5ac7f839b0>))],1,nothing)),("svm",PyObject SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))],Any[ScikitLearn.Skcore.FeatureUnion(Tuple{Any,Any}[("pca",PyObject PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)),("univ_select",PyObject SelectKBest(k=2, score_func=<function f_classif at 0x7f5ac7f839b0>))],1,nothing),PyObject SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)])Testing ../examples/Gaussian_Processes_Julia.ipynb
WARNING: replacing module Testing
(get_params(best_gp))[:logNoise] = 2.5999999999999996
(get_params(best_gp))[:k_lσ] = 4.8
Testing ../examples/Outlier_Detection.ipynb
WARNING: replacing module Testing
Testing ../examples/Pipeline_PCA_Logistic.ipynb
WARNING: replacing module Testing
Testing ../examples/Plot_Kmeans_Digits.ipynb
WARNING: replacing module Testing
n_digits: 10, 	 n_samples 1797, 	 n_features 64
____________________________________________________________________________
init    time  inertia    homo   compl  v-meas     ARI AMI  silhouette
k-means++   0.33s    69662   0.681   0.720   0.700   0.571   0.677    0.135
   random   0.30s    69473   0.606   0.654   0.629   0.476   0.602    0.148
PCA-based   0.04s    70804   0.671   0.698   0.684   0.561   0.668    0.134
____________________________________________________________________________Testing ../examples/Randomized_Search.ipynb
WARNING: replacing module Testing
RandomizedSearchCV took 7.36 seconds for 20 candidates, parameter settings.
Model with rank:1
Mean validation score: 0.927 (std: 0.012)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:max_features,6),Pair{Symbol,Any}(:bootstrap,false),Pair{Symbol,Any}(:min_samples_split,7),Pair{Symbol,Any}(:max_depth,nothing),Pair{Symbol,Any}(:criterion,"gini"),Pair{Symbol,Any}(:min_samples_leaf,4))

Model with rank:2
Mean validation score: 0.922 (std: 0.007)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:max_features,4),Pair{Symbol,Any}(:bootstrap,false),Pair{Symbol,Any}(:min_samples_split,8),Pair{Symbol,Any}(:max_depth,nothing),Pair{Symbol,Any}(:criterion,"entropy"),Pair{Symbol,Any}(:min_samples_leaf,6))

Model with rank:3
Mean validation score: 0.916 (std: 0.023)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:max_features,10),Pair{Symbol,Any}(:bootstrap,false),Pair{Symbol,Any}(:min_samples_split,8),Pair{Symbol,Any}(:max_depth,nothing),Pair{Symbol,Any}(:criterion,"gini"),Pair{Symbol,Any}(:min_samples_leaf,8))

GridSearchCV took 68.48 seconds for 216 candidate parameter settings.
Model with rank:1
Mean validation score: 0.933 (std: 0.009)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:max_features,10),Pair{Symbol,Any}(:bootstrap,false),Pair{Symbol,Any}(:min_samples_split,3),Pair{Symbol,Any}(:max_depth,nothing),Pair{Symbol,Any}(:min_samples_leaf,1),Pair{Symbol,Any}(:criterion,"entropy"))

Model with rank:2
Mean validation score: 0.932 (std: 0.014)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:max_features,10),Pair{Symbol,Any}(:bootstrap,false),Pair{Symbol,Any}(:min_samples_split,2),Pair{Symbol,Any}(:max_depth,nothing),Pair{Symbol,Any}(:min_samples_leaf,3),Pair{Symbol,Any}(:criterion,"entropy"))

Model with rank:3
Mean validation score: 0.932 (std: 0.014)
Parameters: Dict{Symbol,Any}(Pair{Symbol,Any}(:max_features,10),Pair{Symbol,Any}(:bootstrap,false),Pair{Symbol,Any}(:min_samples_split,3),Pair{Symbol,Any}(:max_depth,nothing),Pair{Symbol,Any}(:min_samples_leaf,3),Pair{Symbol,Any}(:criterion,"entropy"))

(predict(random_search,X))[1:10] = [0,1,2,3,4,5,6,7,8,9]
(predict_proba(random_search,X))[1:10] = [1.0,0.0,0.02,0.0,0.144167,0.0,0.0125,0.0,0.0,0.0]
score(random_search,X,y) = 0.9994435169727324
Testing ../examples/RBM.ipynb
WARNING: replacing module Testing
Logistic regression using RBM features:
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       174
          1       0.94      0.95      0.94       184
          2       0.96      0.98      0.97       166
          3       0.96      0.88      0.92       194
          4       0.96      0.95      0.96       186
          5       0.90      0.92      0.91       181
          6       0.99      0.97      0.98       207
          7       0.94      0.98      0.96       154
          8       0.89      0.90      0.89       182
          9       0.90      0.92      0.91       169

avg / total       0.94      0.94      0.94      1797

Logistic regression using raw pixel features:
             precision    recall  f1-score   support

          0       0.86      0.94      0.90       174
          1       0.55      0.53      0.54       184
          2       0.79      0.86      0.82       166
          3       0.78      0.73      0.75       194
          4       0.86      0.83      0.85       186
          5       0.79      0.77      0.78       181
          6       0.89      0.89      0.89       207
          7       0.85      0.93      0.89       154
          8       0.65      0.60      0.63       182
          9       0.71      0.72      0.72       169

avg / total       0.77      0.78      0.78      1797

Testing ../examples/Text_Feature_Extraction.ipynb
WARNING: replacing module Testing
Loading 20 newsgroups dataset for categories:String["alt.atheism","talk.religion.misc"]Downloading 20news dataset. This may take a few minutes.
Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)
857 documents
2 categories

/home/vagrant/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.
  "and default tol will be 1e-3." % type(self), FutureWarning)
Performing grid search...
pipeline:String["vect","tfidf","clf"]
parameters:
Dict{String,Any}(Pair{String,Any}("vect__max_df",(0.5,0.75,1.0)),Pair{String,Any}("clf__penalty",("l2","elasticnet")),Pair{String,Any}("clf__alpha",(1.0e-5,1.0e-6)),Pair{String,Any}("vect__ngram_range",((1,1),(1,2))))
Fitting 3 folds for each of 24 candidates, totalling 72 fits
done in 15.105s
Best score: 0.860
Best parameters set:
	vect__max_df: 1.0
	clf__penalty: elasticnet
	clf__alpha: 1.0e-5
	vect__ngram_range: (1,2)
Testing ../examples/Two_Class_Adaboost.ipynb
WARNING: replacing module Testing
Testing ../examples/Underfitting_vs_Overfitting.ipynb
WARNING: replacing module Testing
[BernoulliRBM] Iteration 1, pseudo-likelihood = -25.54, time = 0.35s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -23.94, time = 0.45s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -22.98, time = 0.45s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.98, time = 0.46s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.48, time = 0.45s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.06, time = 0.45s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -20.93, time = 0.46s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -20.49, time = 0.41s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.27, time = 0.45s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.18, time = 0.47s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -20.02, time = 0.44s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -19.73, time = 0.41s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -19.86, time = 0.42s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -19.64, time = 0.43s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.61, time = 0.40s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -19.40, time = 0.40s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -19.19, time = 0.41s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -19.16, time = 0.40s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -19.13, time = 0.40s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -19.08, time = 0.34s
INFO: ScikitLearn tests passed
INFO: Removing ArrayViews v0.6.4
INFO: Removing Blosc v0.3.0
INFO: Removing Calculus v0.2.2
INFO: Removing Clustering v0.8.0
INFO: Removing ColorTypes v0.5.2
INFO: Removing Colors v0.7.4
INFO: Removing DecisionTree v0.6.2
INFO: Removing DiffBase v0.1.0
INFO: Removing Distances v0.4.1
INFO: Removing Distributions v0.13.0
INFO: Removing FixedPointNumbers v0.3.9
INFO: Removing ForwardDiff v0.4.2
INFO: Removing GaussianMixtures v0.1.0
INFO: Removing GaussianProcesses v0.4.0
INFO: Removing HDF5 v0.8.4
INFO: Removing JLD v0.6.11
INFO: Removing LaTeXStrings v0.2.1
INFO: Removing LegacyStrings v0.2.2
INFO: Removing LineSearches v0.1.5
INFO: Removing LowRankModels v0.2.0
INFO: Removing NBInclude v1.2.0
INFO: Removing NMF v0.2.5
INFO: Removing NaNMath v0.2.6
INFO: Removing NearestNeighbors v0.2.0
INFO: Removing Optim v0.7.8
INFO: Removing PDMats v0.7.0
INFO: Removing PositiveFactorizations v0.0.4
INFO: Removing PyPlot v2.3.2
INFO: Removing QuadGK v0.1.3
INFO: Removing RData v0.1.0
INFO: Removing RDatasets v0.2.0
INFO: Removing Rmath v0.2.0
INFO: Removing Roots v0.4.0
INFO: Removing StaticArrays v0.3.1
INFO: Removing StatsFuns v0.5.0

>>> End of log
