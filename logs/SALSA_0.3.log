>>> 'Pkg.add("SALSA")' log
INFO: Cloning cache of SALSA from git://github.com/jumutc/SALSA.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing BinDeps v0.3.21
INFO: Installing Blosc v0.1.5
INFO: Installing Clustering v0.5.0
INFO: Installing Dates v0.3.2
INFO: Installing Distances v0.2.2
INFO: Installing Distributions v0.8.10
INFO: Installing HDF5 v0.6.3
INFO: Installing HttpCommon v0.1.2
INFO: Installing Iterators v0.1.9
INFO: Installing MAT v0.2.14
INFO: Installing MLBase v0.5.3
INFO: Installing PDMats v0.4.2
INFO: Installing ProgressMeter v0.2.3
INFO: Installing Reexport v0.0.3
INFO: Installing SALSA v0.0.5
INFO: Installing SHA v0.1.2
INFO: Installing StatsBase v0.7.4
INFO: Installing StatsFuns v0.2.2
INFO: Installing URIParser v0.0.7
INFO: Installing Zlib v0.1.12
INFO: Building Blosc
INFO: Building HDF5
INFO: Package database updated

>>> 'Pkg.test("SALSA")' log
Julia Version 0.3.12
Commit 80aa779 (2015-10-26 12:41 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing SALSA
Running tests:
* unit/test_loss_derivative.jl
Warning: New definition 
    kernel_matrix(Kernel,DelimitedFile,Any) at /home/vagrant/.julia/v0.3/SALSA/src/kernels/kernels.jl:31
is ambiguous with: 
    kernel_matrix(Kernel,Any,SubArray{T,N,A<:AbstractArray{T,N},I<:(Union(Range{Int64},Int64)...,)}) at /home/vagrant/.julia/v0.3/SALSA/src/kernels/kernels.jl:29.
To fix, define 
    kernel_matrix(Kernel,DelimitedFile,SubArray{T,N,A<:AbstractArray{T,N},I<:(Union(Range{Int64},Int64)...,)})
before the new definition.
Warning: New definition 
    hinge_loss(SparseMatrixCSC{Tv,Ti<:Integer},Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:59
is ambiguous with: 
    hinge_loss(Any,T<:Number,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:57.
To fix, define 
    hinge_loss(SparseMatrixCSC{Tv,Ti<:Integer},T<:Number,Any)
before the new definition.
Warning: New definition 
    squared_hinge_loss(SparseMatrixCSC{Tv,Ti<:Integer},Any,Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:74
is ambiguous with: 
    squared_hinge_loss(Any,T<:Number,Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:72.
To fix, define 
    squared_hinge_loss(SparseMatrixCSC{Tv,Ti<:Integer},T<:Number,Any,Any)
before the new definition.
Warning: New definition 
    logistic_loss(Array{T,2},Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:95
is ambiguous with: 
    logistic_loss(Any,T<:Number,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:94.
To fix, define 
    logistic_loss(Array{T,2},T<:Number,Any)
before the new definition.
Warning: New definition 
    logistic_loss(Array{T,2},Any,Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:95
is ambiguous with: 
    logistic_loss(Any,T<:Number,Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:94.
To fix, define 
    logistic_loss(Array{T,2},T<:Number,Any,Any)
before the new definition.
Warning: New definition 
    logistic_loss(SparseMatrixCSC{Tv,Ti<:Integer},Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:96
is ambiguous with: 
    logistic_loss(Any,T<:Number,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:94.
To fix, define 
    logistic_loss(SparseMatrixCSC{Tv,Ti<:Integer},T<:Number,Any)
before the new definition.
Warning: New definition 
    logistic_loss(SparseMatrixCSC{Tv,Ti<:Integer},Any,Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:96
is ambiguous with: 
    logistic_loss(Any,T<:Number,Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:94.
To fix, define 
    logistic_loss(SparseMatrixCSC{Tv,Ti<:Integer},T<:Number,Any,Any)
before the new definition.
Warning: New definition 
    least_squares_loss(Any,T<:Number,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:100
is ambiguous with: 
    least_squares_loss(Array{T,2},Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:99.
To fix, define 
    least_squares_loss(Array{T,2},T<:Number,Any)
before the new definition.
Warning: New definition 
    least_squares_loss(SparseMatrixCSC{Tv,Ti<:Integer},Any,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:101
is ambiguous with: 
    least_squares_loss(Any,T<:Number,Any) at /home/vagrant/.julia/v0.3/SALSA/src/loss_derivative.jl:100.
To fix, define 
    least_squares_loss(SparseMatrixCSC{Tv,Ti<:Integer},T<:Number,Any)
before the new definition.


  ____    _    _     ____    _       [31m_ [0m_   | Software Lab for Advanced Machine Learning
 / ___|  / \  | |   / ___|  / \     [31m([31m_[31m) [0m|  | and Stochastic Algorithms in Julia
 \___ \ / _ \ | |   \___ \ / _ \    | | |  |
  ___) / ___ \| |___ ___) / ___ \ [32m_ [0m| | |  | Documentation: http://salsajl.readthedocs.org
 |____/_/   \_\_____|____/_/   \_[32m([32m_[32m)[0m/ |_|  | CI builds: http://travis-ci.org/jumutc/SALSA.jl
                                  |__/     | Version: 0.0.5

* unit/test_pegasos.jl
* unit/test_wrapper.jl
* unit/test_sparse.jl
* unit/test_show.jl
* functional/qa_tables/test_qa.jl
* functional/test_wrapper.jl
* functional/regression/test_fsinc.jl
[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:15[K
CSA results: optimal mean squared error = 0.003
[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:14[K
CSA results: optimal mean squared error = 0.006
* functional/clustering/test_clustering.jl
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:10[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal mean silhouette = 0.502
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:23:55[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:29[K
DS results: optimal mean silhouette = -0.184
* functional/classification/test_linear.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:37[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:36[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:32[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:21[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:15[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:32[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:34[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:32[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:31[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:26[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:21[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:35[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:27[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.160
DS results: optimal AUC (area under curve) = 0.935
DS results: optimal misclassification rate = 0.132
DS results: optimal misclassification rate = 0.128
DS results: optimal misclassification rate = 0.144
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:26[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal weighted combination of: error/sparsity = 0.318
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:20[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.334
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:18[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.222
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:44[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.315
* functional/classification/test_sparse.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:22[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:29[K
CSA results: optimal misclassification rate = 0.132
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:26[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:27[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:21[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:19[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:18[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:13[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:10[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:07[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:04[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:28[K
CSA results: optimal misclassification rate = 0.132
DS results: optimal AUC (area under curve) = 0.935
DS results: optimal misclassification rate = 0.140
DS results: optimal misclassification rate = 0.144
DS results: optimal misclassification rate = 0.160
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:34[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal weighted combination of: error/sparsity = 0.312
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:03:42[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:05[K
DS results: optimal weighted combination of: error/sparsity = 0.245
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:22[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal weighted combination of: error/sparsity = 0.222
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:02:10[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:03[K
DS results: optimal weighted combination of: error/sparsity = 0.318
* functional/classification/test_multiclass.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:01:32[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:01:27[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:01:21[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:01:15[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:01:09[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:01:03[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:57[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:52[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:47[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:43[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:38[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:34[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:24[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:20[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:04[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:01:18[K
CSA results: optimal misclassification rate = 0.373
* functional/classification/test_nonlinear.jl
[1GRunning hyperparameter tuning...   5%|â–ˆ                   |  ETA: 0:00:40[K[1GRunning hyperparameter tuning...  10%|â–ˆâ–ˆ                  |  ETA: 0:00:33[K[1GRunning hyperparameter tuning...  15%|â–ˆâ–ˆâ–ˆ                 |  ETA: 0:00:29[K[1GRunning hyperparameter tuning...  20%|â–ˆâ–ˆâ–ˆâ–ˆ                |  ETA: 0:00:26[K[1GRunning hyperparameter tuning...  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               |  ETA: 0:00:25[K[1GRunning hyperparameter tuning...  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              |  ETA: 0:00:23[K[1GRunning hyperparameter tuning...  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             |  ETA: 0:00:21[K[1GRunning hyperparameter tuning...  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            |  ETA: 0:00:19[K[1GRunning hyperparameter tuning...  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           |  ETA: 0:00:17[K[1GRunning hyperparameter tuning...  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          |  ETA: 0:00:16[K[1GRunning hyperparameter tuning...  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         |  ETA: 0:00:14[K[1GRunning hyperparameter tuning...  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        |  ETA: 0:00:12[K[1GRunning hyperparameter tuning...  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:11[K[1GRunning hyperparameter tuning...  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:09[K[1GRunning hyperparameter tuning...  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:08[K[1GRunning hyperparameter tuning...  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:06[K[1GRunning hyperparameter tuning...  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:05[K[1GRunning hyperparameter tuning...  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:03[K[1GRunning hyperparameter tuning...  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:02[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:31[K
CSA results: optimal misclassification rate = 0.136
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:01:40[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02[K
DS results: optimal misclassification rate = 0.172
DS results: optimal misclassification rate = 0.148
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:04:45[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:06[K
DS results: optimal weighted combination of: error/sparsity = 0.166
[1GRunning hyperparameter tuning...   2%|                    |  ETA: 0:05:32[K[1GRunning hyperparameter tuning... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:07[K
DS results: optimal weighted combination of: error/sparsity = 0.190
INFO: SALSA tests passed
INFO: No packages to install, update or remove

>>> End of log
